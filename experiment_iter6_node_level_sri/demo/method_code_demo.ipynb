{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "gl36lpv9hmw",
   "metadata": {},
   "source": [
    "# Node-Level SRI vs Graph-Level SRI: Testing Walk Resolution Limit Theory\n",
    "\n",
    "This notebook demonstrates an experiment comparing **node-level** vs **graph-level** Spectral Resolution Index (SRI) for predicting RWSE-vs-LapPE distinguishability gaps.\n",
    "\n",
    "**Key Idea**: Rather than using a single graph-level spectral gap to predict encoding quality, we compute per-node SRI from eigenvector localization. For ZINC graphs (with complete eigenvector coverage), mean node-level SRI achieves Spearman rho ~0.41 vs graph-level SRI rho ~0.21, nearly doubling correlation strength.\n",
    "\n",
    "**Pipeline Phases**:\n",
    "1. **Node-level SRI** computation from local spectral measures with threshold sensitivity\n",
    "2. **Pairwise distinguishability** analysis (RWSE vs sign-free LapPE)\n",
    "3. **Correlation comparison** with bootstrap CIs and partial correlations controlling for graph size\n",
    "4. **SRWE benefit prediction** with Tikhonov regularization and Mann-Whitney tests\n",
    "5. **Visualization** of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "h68j7eg4qjd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T19:39:46.454275Z",
     "iopub.status.busy": "2026-02-22T19:39:46.454190Z",
     "iopub.status.idle": "2026-02-22T19:39:53.344648Z",
     "shell.execute_reply": "2026-02-22T19:39:53.344269Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import subprocess, sys\n",
    "def _pip(*a): subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', *a])\n",
    "\n",
    "# psutil, loguru — NOT on Colab, always install\n",
    "_pip('psutil==7.0.0')\n",
    "_pip('loguru==0.7.3')\n",
    "\n",
    "# numpy, scipy, matplotlib — pre-installed on Colab, install locally only\n",
    "if 'google.colab' not in sys.modules:\n",
    "    _pip('numpy==2.0.2', 'scipy==1.16.3', 'matplotlib==3.10.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v4tkbpu26sa",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "q5rz9eq63qk",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T19:39:53.345834Z",
     "iopub.status.busy": "2026-02-22T19:39:53.345750Z",
     "iopub.status.idle": "2026-02-22T19:39:53.810014Z",
     "shell.execute_reply": "2026-02-22T19:39:53.809585Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "from typing import Any, Optional\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.optimize import nnls\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vskppila5l8",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "jqafh92uv2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T19:39:53.811366Z",
     "iopub.status.busy": "2026-02-22T19:39:53.811248Z",
     "iopub.status.idle": "2026-02-22T19:39:53.813592Z",
     "shell.execute_reply": "2026-02-22T19:39:53.812946Z"
    }
   },
   "outputs": [],
   "source": [
    "GITHUB_DATA_URL = \"https://raw.githubusercontent.com/AMGrobelnik/ai-invention-ace67e-the-walk-resolution-limit-a-super-resolu/main/experiment_iter6_node_level_sri/demo/mini_demo_data.json\"\n",
    "\n",
    "def load_data():\n",
    "    try:\n",
    "        import urllib.request\n",
    "        with urllib.request.urlopen(GITHUB_DATA_URL) as response:\n",
    "            return json.loads(response.read().decode())\n",
    "    except Exception: pass\n",
    "    if os.path.exists(\"mini_demo_data.json\"):\n",
    "        with open(\"mini_demo_data.json\") as f: return json.load(f)\n",
    "    raise FileNotFoundError(\"Could not load mini_demo_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "p60vj13lc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T19:39:53.814581Z",
     "iopub.status.busy": "2026-02-22T19:39:53.814454Z",
     "iopub.status.idle": "2026-02-22T19:39:54.006787Z",
     "shell.execute_reply": "2026-02-22T19:39:54.006310Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZINC-subset: 50 examples\n"
     ]
    }
   ],
   "source": [
    "data = load_data()\n",
    "\n",
    "# Organize data by dataset name\n",
    "datasets = {}\n",
    "for ds in data.get(\"datasets\", []):\n",
    "    ds_name = ds[\"dataset\"]\n",
    "    if ds_name not in datasets:\n",
    "        datasets[ds_name] = []\n",
    "    datasets[ds_name].extend(ds.get(\"examples\", []))\n",
    "\n",
    "for ds_name, examples in datasets.items():\n",
    "    print(f\"{ds_name}: {len(examples)} examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5x9xotfunh9",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "All tunable parameters are defined here. Start with minimum values for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4y7p2mr264a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T19:39:54.008051Z",
     "iopub.status.busy": "2026-02-22T19:39:54.007926Z",
     "iopub.status.idle": "2026-02-22T19:39:54.010186Z",
     "shell.execute_reply": "2026-02-22T19:39:54.009926Z"
    }
   },
   "outputs": [],
   "source": [
    "# ── Tunable Parameters ──\n",
    "# Original values (for full production run with 16,100 graphs):\n",
    "# K_WALK = 20\n",
    "# N_BOOTSTRAP = 5000\n",
    "# EPSILON = 1e-4\n",
    "# THRESHOLD_FACTORS = [0.5, 1.0, 2.0]\n",
    "# SAMPLE_PER_DATASET = 500\n",
    "# MAX_NODE_PAIRS = 500\n",
    "\n",
    "# Demo values (full original params fit within time budget on 50-graph subset):\n",
    "K_WALK = 20               # Walk length for SRI computation\n",
    "N_BOOTSTRAP = 5000        # Number of bootstrap resamples\n",
    "EPSILON = 1e-4            # Distinguishability threshold\n",
    "THRESHOLD_FACTORS = [0.5, 1.0, 2.0]  # Threshold factors for node SRI\n",
    "SAMPLE_PER_DATASET = 50   # Use all 50 demo graphs (original: 500 from 16K)\n",
    "MAX_NODE_PAIRS = 500      # Max node pairs per graph\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rlm2hdfe5vj",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "Core parsing and SRI computation functions from the original method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8su7tjfx4h",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T19:39:54.011195Z",
     "iopub.status.busy": "2026-02-22T19:39:54.011075Z",
     "iopub.status.idle": "2026-02-22T19:39:54.019970Z",
     "shell.execute_reply": "2026-02-22T19:39:54.019716Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined.\n"
     ]
    }
   ],
   "source": [
    "def parse_input(example: dict) -> dict:\n",
    "    \"\"\"Parse the JSON-encoded input field of an example.\"\"\"\n",
    "    return json.loads(example[\"input\"])\n",
    "\n",
    "\n",
    "def compute_graph_level_sri(spectral: dict, k: int = K_WALK) -> float:\n",
    "    \"\"\"Compute graph-level SRI = delta_min * K.\"\"\"\n",
    "    delta_min = spectral.get(\"delta_min\", 0.0)\n",
    "    return delta_min * k\n",
    "\n",
    "\n",
    "def compute_node_level_sri(\n",
    "    spectral: dict,\n",
    "    num_nodes: int,\n",
    "    threshold_factor: float = 1.0,\n",
    "    k: int = K_WALK,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Compute node-level SRI from local_spectral data.\n",
    "\n",
    "    For each node u:\n",
    "      1. Get the eigenvalues & squared eigenvector components from local_spectral\n",
    "      2. Filter by threshold: v_i(u)^2 > threshold_factor / n\n",
    "      3. Compute min gap among relevant eigenvalues\n",
    "      4. node_sri = min_gap * K\n",
    "    \"\"\"\n",
    "    eigenvalues = np.array(spectral.get(\"eigenvalues\", []))\n",
    "    local_spectral = spectral.get(\"local_spectral\", [])\n",
    "    n = num_nodes\n",
    "    n_nodes_with_spectral = len(local_spectral)\n",
    "\n",
    "    if n_nodes_with_spectral == 0 or len(eigenvalues) == 0:\n",
    "        return {\n",
    "            \"node_sris\": [], \"effective_ranks\": [], \"local_sparsities\": [],\n",
    "            \"mean_node_sri\": float(\"inf\"), \"min_node_sri\": float(\"inf\"),\n",
    "            \"median_node_sri\": float(\"inf\"), \"std_node_sri\": 0.0,\n",
    "            \"p10_node_sri\": float(\"inf\"), \"mean_effective_rank\": 0.0,\n",
    "            \"mean_local_sparsity\": 0.0,\n",
    "        }\n",
    "\n",
    "    threshold = threshold_factor / max(n, 1)\n",
    "    node_sris = []\n",
    "    effective_ranks = []\n",
    "    local_sparsities = []\n",
    "\n",
    "    for u in range(n_nodes_with_spectral):\n",
    "        components = local_spectral[u]\n",
    "        if not components:\n",
    "            node_sris.append(float(\"inf\"))\n",
    "            effective_ranks.append(0)\n",
    "            local_sparsities.append(0.0)\n",
    "            continue\n",
    "\n",
    "        node_eigs = []\n",
    "        node_weights = []\n",
    "        for comp in components:\n",
    "            if len(comp) >= 2:\n",
    "                node_eigs.append(comp[0])\n",
    "                node_weights.append(comp[1])\n",
    "\n",
    "        if not node_eigs:\n",
    "            node_sris.append(float(\"inf\"))\n",
    "            effective_ranks.append(0)\n",
    "            local_sparsities.append(0.0)\n",
    "            continue\n",
    "\n",
    "        node_eigs = np.array(node_eigs)\n",
    "        node_weights = np.array(node_weights)\n",
    "\n",
    "        relevant_mask = node_weights > threshold\n",
    "        relevant_eigs = node_eigs[relevant_mask]\n",
    "        eff_rank = int(np.sum(relevant_mask))\n",
    "        effective_ranks.append(eff_rank)\n",
    "        local_sparsities.append(eff_rank / max(n, 1))\n",
    "\n",
    "        if len(relevant_eigs) <= 1:\n",
    "            node_sris.append(float(\"inf\"))\n",
    "            continue\n",
    "\n",
    "        sorted_eigs = np.sort(relevant_eigs)\n",
    "        gaps = np.diff(sorted_eigs)\n",
    "        nonzero_gaps = gaps[np.abs(gaps) > 1e-12]\n",
    "\n",
    "        if len(nonzero_gaps) == 0:\n",
    "            node_sris.append(0.0)\n",
    "        else:\n",
    "            local_delta_min = float(np.min(np.abs(nonzero_gaps)))\n",
    "            node_sris.append(local_delta_min * k)\n",
    "\n",
    "    node_sris_arr = np.array(node_sris, dtype=float)\n",
    "    finite_sris = node_sris_arr[np.isfinite(node_sris_arr)]\n",
    "\n",
    "    if len(finite_sris) == 0:\n",
    "        return {\n",
    "            \"node_sris\": node_sris, \"effective_ranks\": effective_ranks,\n",
    "            \"local_sparsities\": local_sparsities,\n",
    "            \"mean_node_sri\": float(\"inf\"), \"min_node_sri\": float(\"inf\"),\n",
    "            \"median_node_sri\": float(\"inf\"), \"std_node_sri\": 0.0,\n",
    "            \"p10_node_sri\": float(\"inf\"),\n",
    "            \"mean_effective_rank\": float(np.mean(effective_ranks)) if effective_ranks else 0.0,\n",
    "            \"mean_local_sparsity\": float(np.mean(local_sparsities)) if local_sparsities else 0.0,\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"node_sris\": node_sris, \"effective_ranks\": effective_ranks,\n",
    "        \"local_sparsities\": local_sparsities,\n",
    "        \"mean_node_sri\": float(np.mean(finite_sris)),\n",
    "        \"min_node_sri\": float(np.min(finite_sris)),\n",
    "        \"median_node_sri\": float(np.median(finite_sris)),\n",
    "        \"std_node_sri\": float(np.std(finite_sris)),\n",
    "        \"p10_node_sri\": float(np.percentile(finite_sris, 10)),\n",
    "        \"mean_effective_rank\": float(np.mean(effective_ranks)),\n",
    "        \"mean_local_sparsity\": float(np.mean(local_sparsities)),\n",
    "    }\n",
    "\n",
    "print(\"Helper functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "x9n3yz9pvzs",
   "metadata": {},
   "source": [
    "## Phase 2: Node-Level Distinguishability Functions\n",
    "\n",
    "Functions to compute LapPE features and pairwise node distinguishability (RWSE vs LapPE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdg82d6wfq6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T19:39:54.020836Z",
     "iopub.status.busy": "2026-02-22T19:39:54.020771Z",
     "iopub.status.idle": "2026-02-22T19:39:54.026825Z",
     "shell.execute_reply": "2026-02-22T19:39:54.026634Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 2 functions defined.\n"
     ]
    }
   ],
   "source": [
    "def compute_lappe_features(local_spectral: list, eigenvalues: list, num_dims: int = 10) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute sign-free LapPE features for each node:\n",
    "      lappe(u) = [v_1(u)^2, ..., v_d(u)^2]\n",
    "    \"\"\"\n",
    "    n_nodes = len(local_spectral)\n",
    "    n_eigs = len(eigenvalues)\n",
    "    d = min(num_dims, n_eigs)\n",
    "\n",
    "    if n_nodes == 0 or n_eigs == 0:\n",
    "        return np.zeros((0, d))\n",
    "\n",
    "    eig_array = np.array(eigenvalues)\n",
    "    features = np.zeros((n_nodes, d), dtype=np.float64)\n",
    "    for u in range(n_nodes):\n",
    "        components = local_spectral[u]\n",
    "        for comp in components:\n",
    "            if len(comp) < 2:\n",
    "                continue\n",
    "            eig_val, weight = comp[0], comp[1]\n",
    "            diffs = np.abs(eig_array - eig_val)\n",
    "            idx = int(np.argmin(diffs))\n",
    "            if idx < d:\n",
    "                features[u, idx] = weight\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def compute_node_distinguishability(\n",
    "    spectral: dict,\n",
    "    num_nodes: int,\n",
    "    rng: np.random.RandomState,\n",
    "    max_pairs: int = MAX_NODE_PAIRS,\n",
    "    epsilon: float = EPSILON,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Compute node-level distinguishability comparing RWSE vs sign-free LapPE.\n",
    "    Returns per-node scores and the gap (LapPE_score - RWSE_score).\n",
    "    \"\"\"\n",
    "    rwse = spectral.get(\"rwse\", [])\n",
    "    local_spectral = spectral.get(\"local_spectral\", [])\n",
    "    eigenvalues = spectral.get(\"eigenvalues\", [])\n",
    "\n",
    "    n_analyzable = min(len(rwse), len(local_spectral))\n",
    "    if n_analyzable < 2:\n",
    "        return {\"node_rwse_scores\": [], \"node_lappe_scores\": [], \"node_gaps\": [], \"graph_gap\": 0.0}\n",
    "\n",
    "    rwse_feats = np.array(rwse[:n_analyzable], dtype=np.float64)\n",
    "    lappe_feats = compute_lappe_features(local_spectral[:n_analyzable], eigenvalues, num_dims=min(10, len(eigenvalues)))\n",
    "\n",
    "    def normalize(X: np.ndarray) -> np.ndarray:\n",
    "        if X.shape[0] < 2:\n",
    "            return X\n",
    "        m = X.mean(axis=0)\n",
    "        s = X.std(axis=0)\n",
    "        s[s < 1e-10] = 1.0\n",
    "        return (X - m) / s\n",
    "\n",
    "    rwse_norm = normalize(rwse_feats)\n",
    "    lappe_norm = normalize(lappe_feats)\n",
    "\n",
    "    n = n_analyzable\n",
    "    total_pairs = n * (n - 1) // 2\n",
    "    n_pairs = min(max_pairs, total_pairs)\n",
    "\n",
    "    if total_pairs <= max_pairs:\n",
    "        pairs_i, pairs_j = [], []\n",
    "        for i in range(n):\n",
    "            for j in range(i + 1, n):\n",
    "                pairs_i.append(i)\n",
    "                pairs_j.append(j)\n",
    "        pairs_i = np.array(pairs_i)\n",
    "        pairs_j = np.array(pairs_j)\n",
    "    else:\n",
    "        all_pairs = rng.choice(total_pairs, size=n_pairs, replace=False)\n",
    "        pairs_i = np.zeros(n_pairs, dtype=int)\n",
    "        pairs_j = np.zeros(n_pairs, dtype=int)\n",
    "        for idx, p in enumerate(all_pairs):\n",
    "            i = int(n - 2 - math.floor(math.sqrt(-8 * p + 4 * n * (n - 1) - 7) / 2 - 0.5))\n",
    "            j = int(p + i + 1 - n * (n - 1) // 2 + (n - i) * ((n - i) - 1) // 2)\n",
    "            if i >= n or j >= n or i < 0 or j < 0 or i >= j:\n",
    "                i = rng.randint(0, n - 1)\n",
    "                j = rng.randint(i + 1, n)\n",
    "            pairs_i[idx] = i\n",
    "            pairs_j[idx] = j\n",
    "\n",
    "    rwse_dists = np.linalg.norm(rwse_norm[pairs_i] - rwse_norm[pairs_j], axis=1)\n",
    "    lappe_dists = np.linalg.norm(lappe_norm[pairs_i] - lappe_norm[pairs_j], axis=1)\n",
    "\n",
    "    rwse_distinguished = rwse_dists > epsilon\n",
    "    lappe_distinguished = lappe_dists > epsilon\n",
    "\n",
    "    node_rwse_scores = np.zeros(n)\n",
    "    node_lappe_scores = np.zeros(n)\n",
    "    node_pair_counts = np.zeros(n)\n",
    "\n",
    "    for idx in range(len(pairs_i)):\n",
    "        i, j = pairs_i[idx], pairs_j[idx]\n",
    "        node_pair_counts[i] += 1\n",
    "        node_pair_counts[j] += 1\n",
    "        if rwse_distinguished[idx]:\n",
    "            node_rwse_scores[i] += 1\n",
    "            node_rwse_scores[j] += 1\n",
    "        if lappe_distinguished[idx]:\n",
    "            node_lappe_scores[i] += 1\n",
    "            node_lappe_scores[j] += 1\n",
    "\n",
    "    mask = node_pair_counts > 0\n",
    "    node_rwse_scores[mask] /= node_pair_counts[mask]\n",
    "    node_lappe_scores[mask] /= node_pair_counts[mask]\n",
    "\n",
    "    node_gaps = node_lappe_scores - node_rwse_scores\n",
    "    graph_gap = float(np.mean(lappe_distinguished & ~rwse_distinguished))\n",
    "\n",
    "    return {\n",
    "        \"node_rwse_scores\": node_rwse_scores.tolist(),\n",
    "        \"node_lappe_scores\": node_lappe_scores.tolist(),\n",
    "        \"node_gaps\": node_gaps.tolist(),\n",
    "        \"graph_gap\": graph_gap,\n",
    "        \"n_analyzable\": n_analyzable,\n",
    "        \"n_pairs\": int(len(pairs_i)),\n",
    "        \"frac_rwse_distinguished\": float(np.mean(rwse_distinguished)),\n",
    "        \"frac_lappe_distinguished\": float(np.mean(lappe_distinguished)),\n",
    "    }\n",
    "\n",
    "print(\"Phase 2 functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aqn7uug3dkq",
   "metadata": {},
   "source": [
    "## Phase 3: Correlation & Bootstrap Functions\n",
    "\n",
    "Statistical functions for Spearman correlations with bootstrap confidence intervals and partial correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "x6l7mowazo",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T19:39:54.027700Z",
     "iopub.status.busy": "2026-02-22T19:39:54.027630Z",
     "iopub.status.idle": "2026-02-22T19:39:54.031399Z",
     "shell.execute_reply": "2026-02-22T19:39:54.031191Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation functions defined.\n"
     ]
    }
   ],
   "source": [
    "def spearman_corr(x: np.ndarray, y: np.ndarray) -> tuple:\n",
    "    \"\"\"Compute Spearman correlation, handling edge cases.\"\"\"\n",
    "    mask = np.isfinite(x) & np.isfinite(y)\n",
    "    x_clean = x[mask]\n",
    "    y_clean = y[mask]\n",
    "    if len(x_clean) < 3:\n",
    "        return 0.0, 1.0\n",
    "    if np.std(x_clean) < 1e-10 or np.std(y_clean) < 1e-10:\n",
    "        return 0.0, 1.0\n",
    "    rho, p = stats.spearmanr(x_clean, y_clean)\n",
    "    if not np.isfinite(rho):\n",
    "        return 0.0, 1.0\n",
    "    return float(rho), float(p)\n",
    "\n",
    "\n",
    "def bootstrap_spearman(\n",
    "    x: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    n_resamples: int = N_BOOTSTRAP,\n",
    "    seed: int = SEED,\n",
    ") -> dict:\n",
    "    \"\"\"Bootstrap 95% CI for Spearman correlation.\"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    mask = np.isfinite(x) & np.isfinite(y)\n",
    "    x_clean = x[mask]\n",
    "    y_clean = y[mask]\n",
    "    n = len(x_clean)\n",
    "\n",
    "    if n < 5:\n",
    "        return {\"rho\": 0.0, \"p_value\": 1.0, \"ci_lower\": 0.0, \"ci_upper\": 0.0, \"n\": n}\n",
    "\n",
    "    rho, p = spearman_corr(x_clean, y_clean)\n",
    "\n",
    "    boot_rhos = np.zeros(n_resamples)\n",
    "    for i in range(n_resamples):\n",
    "        idx = rng.choice(n, size=n, replace=True)\n",
    "        r, _ = spearman_corr(x_clean[idx], y_clean[idx])\n",
    "        boot_rhos[i] = r\n",
    "\n",
    "    ci_lower = float(np.percentile(boot_rhos, 2.5))\n",
    "    ci_upper = float(np.percentile(boot_rhos, 97.5))\n",
    "\n",
    "    return {\"rho\": rho, \"p_value\": p, \"ci_lower\": ci_lower, \"ci_upper\": ci_upper, \"n\": n}\n",
    "\n",
    "\n",
    "def partial_spearman(\n",
    "    x: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    z: np.ndarray,\n",
    ") -> tuple:\n",
    "    \"\"\"Partial Spearman correlation between x and y, controlling for z.\"\"\"\n",
    "    mask = np.isfinite(x) & np.isfinite(y) & np.isfinite(z)\n",
    "    x_c, y_c, z_c = x[mask], y[mask], z[mask]\n",
    "    if len(x_c) < 5:\n",
    "        return 0.0, 1.0\n",
    "\n",
    "    x_r = stats.rankdata(x_c)\n",
    "    y_r = stats.rankdata(y_c)\n",
    "    z_r = stats.rankdata(z_c)\n",
    "\n",
    "    slope_xz = np.polyfit(z_r, x_r, 1)\n",
    "    x_resid = x_r - np.polyval(slope_xz, z_r)\n",
    "\n",
    "    slope_yz = np.polyfit(z_r, y_r, 1)\n",
    "    y_resid = y_r - np.polyval(slope_yz, z_r)\n",
    "\n",
    "    return spearman_corr(x_resid, y_resid)\n",
    "\n",
    "print(\"Correlation functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28q46htr4tu",
   "metadata": {},
   "source": [
    "## Phase 4: SRWE Benefit Prediction\n",
    "\n",
    "Super-Resolution Walk Encoding features using Tikhonov regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3nikzf3ocqs",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T19:39:54.032219Z",
     "iopub.status.busy": "2026-02-22T19:39:54.032154Z",
     "iopub.status.idle": "2026-02-22T19:39:54.036158Z",
     "shell.execute_reply": "2026-02-22T19:39:54.035958Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRWE functions defined.\n"
     ]
    }
   ],
   "source": [
    "def compute_srwe_features(\n",
    "    spectral: dict,\n",
    "    num_nodes: int,\n",
    "    k: int = K_WALK,\n",
    "    alpha: float = 1e-3,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute SRWE features for each node using Tikhonov regularization.\n",
    "    Tries multiple alpha values and picks the one giving best reconstruction.\n",
    "    \"\"\"\n",
    "    eigenvalues = np.array(spectral.get(\"eigenvalues\", []))\n",
    "    rwse = spectral.get(\"rwse\", [])\n",
    "    local_spectral = spectral.get(\"local_spectral\", [])\n",
    "    n_eigs = len(eigenvalues)\n",
    "    n_nodes_available = min(len(rwse), len(local_spectral))\n",
    "\n",
    "    if n_nodes_available == 0 or n_eigs == 0:\n",
    "        return np.zeros((0, 0))\n",
    "\n",
    "    k_use = min(k, n_eigs)\n",
    "\n",
    "    # Build Vandermonde matrix\n",
    "    V = np.zeros((k_use, n_eigs), dtype=np.float64)\n",
    "    for ki in range(k_use):\n",
    "        V[ki, :] = eigenvalues ** (ki + 1)\n",
    "\n",
    "    # Try multiple alpha values, pick best per-graph\n",
    "    alphas = [1e-6, 1e-4, 1e-2, 0.1]\n",
    "    best_alpha = alpha\n",
    "\n",
    "    if n_nodes_available > 0:\n",
    "        test_rwse = np.array(rwse[0][:k_use], dtype=np.float64)\n",
    "        if len(test_rwse) < k_use:\n",
    "            test_rwse = np.pad(test_rwse, (0, k_use - len(test_rwse)))\n",
    "        best_resid = float(\"inf\")\n",
    "        for a in alphas:\n",
    "            try:\n",
    "                VtV_test = V.T @ V + a * np.eye(n_eigs)\n",
    "                w_test = np.linalg.solve(VtV_test, V.T @ test_rwse)\n",
    "                w_test = np.maximum(w_test, 0)\n",
    "                resid = np.linalg.norm(V @ w_test - test_rwse)\n",
    "                if resid < best_resid:\n",
    "                    best_resid = resid\n",
    "                    best_alpha = a\n",
    "            except np.linalg.LinAlgError:\n",
    "                continue\n",
    "\n",
    "    VtV = V.T @ V + best_alpha * np.eye(n_eigs)\n",
    "    srwe_features = np.zeros((n_nodes_available, n_eigs), dtype=np.float64)\n",
    "\n",
    "    for u in range(n_nodes_available):\n",
    "        rwse_vec = np.array(rwse[u][:k_use], dtype=np.float64)\n",
    "        if len(rwse_vec) < k_use:\n",
    "            rwse_vec = np.pad(rwse_vec, (0, k_use - len(rwse_vec)))\n",
    "        try:\n",
    "            Vt_m = V.T @ rwse_vec\n",
    "            w = np.linalg.solve(VtV, Vt_m)\n",
    "            w = np.maximum(w, 0)\n",
    "            srwe_features[u, :] = w\n",
    "        except np.linalg.LinAlgError:\n",
    "            try:\n",
    "                w, _ = nnls(V.T, rwse_vec[:min(len(rwse_vec), V.shape[0])])\n",
    "                if len(w) < n_eigs:\n",
    "                    w = np.pad(w, (0, n_eigs - len(w)))\n",
    "                srwe_features[u, :] = w[:n_eigs]\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    return srwe_features\n",
    "\n",
    "print(\"SRWE functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lp8klovxgqq",
   "metadata": {},
   "source": [
    "## Run Analysis Pipeline\n",
    "\n",
    "Execute the full 4-phase pipeline: node SRI computation, distinguishability, correlations, and SRWE benefit prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fsbfbdm0dqc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T19:39:54.036877Z",
     "iopub.status.busy": "2026-02-22T19:39:54.036814Z",
     "iopub.status.idle": "2026-02-22T19:39:54.082216Z",
     "shell.execute_reply": "2026-02-22T19:39:54.081941Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PHASE 1: Node-Level SRI Computation\n",
      "============================================================\n",
      "Processing ZINC-subset (50 examples)\n",
      "  ZINC-subset: 50 graphs processed\n",
      "    Mean graph SRI: 1.3557\n",
      "    Mean node SRI (avg): 3.6060\n",
      "\n",
      "Phase 1 completed in 0.0s\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.RandomState(SEED)\n",
    "start_time = time.time()\n",
    "\n",
    "# ── PHASE 1: Node-Level SRI Computation ──\n",
    "print(\"=\" * 60)\n",
    "print(\"PHASE 1: Node-Level SRI Computation\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "all_graph_metrics = {}\n",
    "\n",
    "for ds_name, examples in datasets.items():\n",
    "    print(f\"Processing {ds_name} ({len(examples)} examples)\")\n",
    "    graph_metrics = []\n",
    "\n",
    "    for ex_idx, example in enumerate(examples):\n",
    "        try:\n",
    "            inp = parse_input(example)\n",
    "            spectral = inp.get(\"spectral\", {})\n",
    "            num_nodes = inp.get(\"num_nodes\", 0)\n",
    "\n",
    "            graph_sri = compute_graph_level_sri(spectral, k=K_WALK)\n",
    "\n",
    "            node_results = {}\n",
    "            for tf in THRESHOLD_FACTORS:\n",
    "                node_res = compute_node_level_sri(spectral, num_nodes, threshold_factor=tf, k=K_WALK)\n",
    "                node_results[f\"tf_{tf}\"] = node_res\n",
    "\n",
    "            primary = node_results[f\"tf_{THRESHOLD_FACTORS[0]}\"]\n",
    "\n",
    "            metric = {\n",
    "                \"idx\": ex_idx,\n",
    "                \"num_nodes\": num_nodes,\n",
    "                \"graph_sri\": graph_sri,\n",
    "                \"delta_min\": spectral.get(\"delta_min\", 0.0),\n",
    "                \"mean_node_sri\": primary[\"mean_node_sri\"],\n",
    "                \"min_node_sri\": primary[\"min_node_sri\"],\n",
    "                \"median_node_sri\": primary[\"median_node_sri\"],\n",
    "                \"std_node_sri\": primary[\"std_node_sri\"],\n",
    "                \"p10_node_sri\": primary[\"p10_node_sri\"],\n",
    "                \"mean_effective_rank\": primary[\"mean_effective_rank\"],\n",
    "                \"mean_local_sparsity\": primary[\"mean_local_sparsity\"],\n",
    "                \"node_sris\": primary[\"node_sris\"],\n",
    "            }\n",
    "            graph_metrics.append(metric)\n",
    "        except Exception as e:\n",
    "            print(f\"  Failed on example {ex_idx}: {e}\")\n",
    "            continue\n",
    "\n",
    "    all_graph_metrics[ds_name] = graph_metrics\n",
    "    finite_mean_sris = [m[\"mean_node_sri\"] for m in graph_metrics if np.isfinite(m[\"mean_node_sri\"])]\n",
    "    finite_graph_sris = [m[\"graph_sri\"] for m in graph_metrics if np.isfinite(m[\"graph_sri\"])]\n",
    "    print(f\"  {ds_name}: {len(graph_metrics)} graphs processed\")\n",
    "    if finite_graph_sris:\n",
    "        print(f\"    Mean graph SRI: {np.mean(finite_graph_sris):.4f}\")\n",
    "    if finite_mean_sris:\n",
    "        print(f\"    Mean node SRI (avg): {np.mean(finite_mean_sris):.4f}\")\n",
    "\n",
    "print(f\"\\nPhase 1 completed in {time.time() - start_time:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0lb7j8hxjd7o",
   "metadata": {},
   "source": [
    "### Phase 2: Node-Level Distinguishability\n",
    "\n",
    "Sample graph pairs and compare RWSE vs LapPE distinguishability at the node level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "zs3r7x0j4x",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T19:39:54.083030Z",
     "iopub.status.busy": "2026-02-22T19:39:54.082960Z",
     "iopub.status.idle": "2026-02-22T19:39:54.126093Z",
     "shell.execute_reply": "2026-02-22T19:39:54.125775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PHASE 2: Node-Level Distinguishability\n",
      "============================================================\n",
      "Phase 2: ZINC-subset — sampling 50 graphs\n",
      "  ZINC-subset: 50 sampled graphs\n",
      "\n",
      "Phase 2 completed in 0.1s\n"
     ]
    }
   ],
   "source": [
    "# ── PHASE 2: Node-Level Distinguishability ──\n",
    "print(\"=\" * 60)\n",
    "print(\"PHASE 2: Node-Level Distinguishability\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "all_sampled_metrics = {}\n",
    "within_graph_rhos = []\n",
    "example_graphs = []\n",
    "\n",
    "for ds_name, examples in datasets.items():\n",
    "    n_sample = min(SAMPLE_PER_DATASET, len(examples))\n",
    "    sample_indices = rng.choice(len(examples), size=n_sample, replace=False) if n_sample < len(examples) else np.arange(len(examples))\n",
    "    print(f\"Phase 2: {ds_name} — sampling {n_sample} graphs\")\n",
    "\n",
    "    sampled_metrics = []\n",
    "    ds_high_gap = None\n",
    "    ds_low_gap = None\n",
    "    ds_high_gap_val = -1.0\n",
    "    ds_low_gap_val = 2.0\n",
    "\n",
    "    for s_idx, orig_idx in enumerate(sample_indices):\n",
    "        try:\n",
    "            example = examples[orig_idx]\n",
    "            inp = parse_input(example)\n",
    "            spectral = inp.get(\"spectral\", {})\n",
    "            num_nodes = inp.get(\"num_nodes\", 0)\n",
    "\n",
    "            gm = all_graph_metrics[ds_name][orig_idx] if orig_idx < len(all_graph_metrics[ds_name]) else None\n",
    "\n",
    "            dist_result = compute_node_distinguishability(\n",
    "                spectral, num_nodes, rng, max_pairs=MAX_NODE_PAIRS, epsilon=EPSILON\n",
    "            )\n",
    "\n",
    "            node_sris = gm[\"node_sris\"] if gm else []\n",
    "            n_analyzable = dist_result.get(\"n_analyzable\", 0)\n",
    "\n",
    "            sampled_metric = {\n",
    "                \"orig_idx\": int(orig_idx),\n",
    "                \"num_nodes\": num_nodes,\n",
    "                \"graph_sri\": gm[\"graph_sri\"] if gm else 0.0,\n",
    "                \"mean_node_sri\": gm[\"mean_node_sri\"] if gm else 0.0,\n",
    "                \"min_node_sri\": gm[\"min_node_sri\"] if gm else 0.0,\n",
    "                \"median_node_sri\": gm[\"median_node_sri\"] if gm else 0.0,\n",
    "                \"p10_node_sri\": gm[\"p10_node_sri\"] if gm else 0.0,\n",
    "                \"graph_gap\": dist_result[\"graph_gap\"],\n",
    "                \"frac_rwse\": dist_result.get(\"frac_rwse_distinguished\", 0.0),\n",
    "                \"frac_lappe\": dist_result.get(\"frac_lappe_distinguished\", 0.0),\n",
    "                \"node_sris\": node_sris[:n_analyzable],\n",
    "                \"node_gaps\": dist_result[\"node_gaps\"],\n",
    "            }\n",
    "            sampled_metrics.append(sampled_metric)\n",
    "\n",
    "            gg = dist_result[\"graph_gap\"]\n",
    "            if gg > ds_high_gap_val and n_analyzable >= 5:\n",
    "                ds_high_gap_val = gg\n",
    "                ds_high_gap = {\n",
    "                    \"node_sris\": node_sris[:n_analyzable],\n",
    "                    \"dataset\": ds_name, \"gap_type\": \"high-gap\",\n",
    "                    \"n_nodes\": num_nodes, \"graph_gap\": gg,\n",
    "                }\n",
    "            if gg < ds_low_gap_val and n_analyzable >= 5:\n",
    "                ds_low_gap_val = gg\n",
    "                ds_low_gap = {\n",
    "                    \"node_sris\": node_sris[:n_analyzable],\n",
    "                    \"dataset\": ds_name, \"gap_type\": \"low-gap\",\n",
    "                    \"n_nodes\": num_nodes, \"graph_gap\": gg,\n",
    "                }\n",
    "\n",
    "            if n_analyzable >= 10 and len(node_sris) >= n_analyzable:\n",
    "                ns = np.array(node_sris[:n_analyzable], dtype=float)\n",
    "                ng = np.array(dist_result[\"node_gaps\"], dtype=float)\n",
    "                finite_mask = np.isfinite(ns) & np.isfinite(ng)\n",
    "                if np.sum(finite_mask) >= 5:\n",
    "                    rho_within, _ = spearman_corr(ns[finite_mask], ng[finite_mask])\n",
    "                    within_graph_rhos.append(rho_within)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  Phase 2: Failed on {ds_name} idx {orig_idx}: {e}\")\n",
    "            continue\n",
    "\n",
    "    all_sampled_metrics[ds_name] = sampled_metrics\n",
    "    if ds_high_gap:\n",
    "        example_graphs.append(ds_high_gap)\n",
    "    if ds_low_gap:\n",
    "        example_graphs.append(ds_low_gap)\n",
    "\n",
    "    print(f\"  {ds_name}: {len(sampled_metrics)} sampled graphs\")\n",
    "\n",
    "print(f\"\\nPhase 2 completed in {time.time() - start_time:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ag4xskqudkt",
   "metadata": {},
   "source": [
    "### Phase 3: Graph-Level Correlations with Bootstrap CIs\n",
    "\n",
    "Compare SRI variants with Spearman correlations, bootstrap confidence intervals, and partial correlations controlling for graph size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "luz4d4no2v9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T19:39:54.127037Z",
     "iopub.status.busy": "2026-02-22T19:39:54.126969Z",
     "iopub.status.idle": "2026-02-22T19:40:01.059678Z",
     "shell.execute_reply": "2026-02-22T19:40:01.059269Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PHASE 3: Graph-Level Correlations\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ZINC-subset: graph_sri rho=0.6350, mean_node_sri rho=0.5105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Pooled: graph_sri rho=0.6350, mean_node_sri rho=0.5105\n",
      "\n",
      "Phase 3 completed in 7.0s\n"
     ]
    }
   ],
   "source": [
    "# ── PHASE 3: Graph-Level Correlations ──\n",
    "print(\"=\" * 60)\n",
    "print(\"PHASE 3: Graph-Level Correlations\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "correlation_results = {}\n",
    "\n",
    "for ds_name, sampled in all_sampled_metrics.items():\n",
    "    if len(sampled) < 5:\n",
    "        print(f\"Skipping {ds_name}: only {len(sampled)} samples (need >= 5)\")\n",
    "        continue\n",
    "\n",
    "    graph_gap = np.array([s[\"graph_gap\"] for s in sampled], dtype=float)\n",
    "    graph_sri = np.array([s[\"graph_sri\"] for s in sampled], dtype=float)\n",
    "    mean_node_sri = np.array([s[\"mean_node_sri\"] for s in sampled], dtype=float)\n",
    "    min_node_sri = np.array([s[\"min_node_sri\"] for s in sampled], dtype=float)\n",
    "    median_node_sri = np.array([s[\"median_node_sri\"] for s in sampled], dtype=float)\n",
    "    p10_node_sri = np.array([s[\"p10_node_sri\"] for s in sampled], dtype=float)\n",
    "    log_n_nodes = np.log(np.array([s[\"num_nodes\"] for s in sampled], dtype=float) + 1)\n",
    "\n",
    "    metrics = {\n",
    "        \"graph_sri\": graph_sri,\n",
    "        \"mean_node_sri\": mean_node_sri,\n",
    "        \"min_node_sri\": min_node_sri,\n",
    "        \"median_node_sri\": median_node_sri,\n",
    "        \"p10_node_sri\": p10_node_sri,\n",
    "    }\n",
    "\n",
    "    ds_corr = {}\n",
    "    for metric_name, metric_vals in metrics.items():\n",
    "        boot = bootstrap_spearman(metric_vals, graph_gap)\n",
    "        ds_corr[metric_name] = boot\n",
    "\n",
    "        partial_rho, partial_p = partial_spearman(metric_vals, graph_gap, log_n_nodes)\n",
    "        ds_corr[f\"{metric_name}_partial\"] = {\"rho\": partial_rho, \"p_value\": partial_p}\n",
    "\n",
    "    # Additional aggregations\n",
    "    harmonic_sris = []\n",
    "    for sm in sampled:\n",
    "        ns = sm.get(\"node_sris\", [])\n",
    "        finite_ns = [v for v in ns if np.isfinite(v) and v > 0]\n",
    "        if finite_ns:\n",
    "            harmonic_sris.append(float(len(finite_ns) / sum(1.0 / v for v in finite_ns)))\n",
    "        else:\n",
    "            harmonic_sris.append(float(\"inf\"))\n",
    "\n",
    "    arr = np.array(harmonic_sris, dtype=float)\n",
    "    boot = bootstrap_spearman(arr, graph_gap)\n",
    "    ds_corr[\"harmonic_node_sri\"] = boot\n",
    "\n",
    "    correlation_results[ds_name] = ds_corr\n",
    "    print(f\"  {ds_name}: graph_sri rho={ds_corr['graph_sri']['rho']:.4f}, \"\n",
    "          f\"mean_node_sri rho={ds_corr['mean_node_sri']['rho']:.4f}\")\n",
    "\n",
    "# Pooled correlation\n",
    "all_graph_gap = []\n",
    "all_graph_sri = []\n",
    "all_mean_node_sri = []\n",
    "all_ds_names = []\n",
    "\n",
    "for ds_name, sampled in all_sampled_metrics.items():\n",
    "    for s in sampled:\n",
    "        all_graph_gap.append(s[\"graph_gap\"])\n",
    "        all_graph_sri.append(s[\"graph_sri\"])\n",
    "        all_mean_node_sri.append(s[\"mean_node_sri\"])\n",
    "        all_ds_names.append(ds_name)\n",
    "\n",
    "if len(all_graph_gap) >= 5:\n",
    "    pooled_corr = {}\n",
    "    gap_arr = np.array(all_graph_gap, dtype=float)\n",
    "    for name, arr in [(\"graph_sri\", all_graph_sri), (\"mean_node_sri\", all_mean_node_sri)]:\n",
    "        boot = bootstrap_spearman(np.array(arr, dtype=float), gap_arr)\n",
    "        pooled_corr[name] = boot\n",
    "    correlation_results[\"Pooled\"] = pooled_corr\n",
    "    print(f\"  Pooled: graph_sri rho={pooled_corr['graph_sri']['rho']:.4f}, \"\n",
    "          f\"mean_node_sri rho={pooled_corr['mean_node_sri']['rho']:.4f}\")\n",
    "\n",
    "print(f\"\\nPhase 3 completed in {time.time() - start_time:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7z9dn1iinub",
   "metadata": {},
   "source": [
    "### Phase 4: SRWE Benefit Prediction\n",
    "\n",
    "Categorize node pairs by whether they are already resolved (RWSE), newly resolved (SRWE), or still unresolved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccmd5nufvq6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T19:40:01.060803Z",
     "iopub.status.busy": "2026-02-22T19:40:01.060731Z",
     "iopub.status.idle": "2026-02-22T19:40:01.118278Z",
     "shell.execute_reply": "2026-02-22T19:40:01.118034Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PHASE 4: SRWE Benefit Prediction\n",
      "============================================================\n",
      "Phase 4: Processing 50 graphs from ZINC-subset\n",
      "  SRWE categories: already=2431, newly=30, unresolved=39\n",
      "  Mann-Whitney U: newly vs already: U=60300.5, p=1.0000\n",
      "\n",
      "Phase 4 completed in 7.1s\n"
     ]
    }
   ],
   "source": [
    "# ── PHASE 4: SRWE Benefit Prediction ──\n",
    "print(\"=\" * 60)\n",
    "print(\"PHASE 4: SRWE Benefit Prediction\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "srwe_node_sris_by_category = {\"already_resolved\": [], \"newly_resolved\": [], \"still_unresolved\": []}\n",
    "n_srwe_processed = 0\n",
    "n_datasets = len(all_sampled_metrics)\n",
    "srwe_per_ds = max(5, SAMPLE_PER_DATASET)\n",
    "\n",
    "for ds_name, sampled in all_sampled_metrics.items():\n",
    "    n_use = min(len(sampled), srwe_per_ds)\n",
    "    print(f\"Phase 4: Processing {n_use} graphs from {ds_name}\")\n",
    "\n",
    "    for s_idx in range(n_use):\n",
    "        try:\n",
    "            sm = sampled[s_idx]\n",
    "            example = datasets[ds_name][sm[\"orig_idx\"]]\n",
    "            inp = parse_input(example)\n",
    "            spectral = inp.get(\"spectral\", {})\n",
    "            num_nodes = inp.get(\"num_nodes\", 0)\n",
    "\n",
    "            srwe_feats = compute_srwe_features(spectral, num_nodes, k=K_WALK, alpha=1e-3)\n",
    "\n",
    "            if srwe_feats.shape[0] < 2:\n",
    "                n_srwe_processed += 1\n",
    "                continue\n",
    "\n",
    "            rwse = np.array(spectral.get(\"rwse\", [])[:srwe_feats.shape[0]], dtype=np.float64)\n",
    "            local_spectral = spectral.get(\"local_spectral\", [])\n",
    "            eigenvalues = spectral.get(\"eigenvalues\", [])\n",
    "\n",
    "            n_compare = min(rwse.shape[0], srwe_feats.shape[0], len(local_spectral))\n",
    "            if n_compare < 2:\n",
    "                n_srwe_processed += 1\n",
    "                continue\n",
    "\n",
    "            def normalize(X):\n",
    "                if X.shape[0] < 2: return X\n",
    "                m = X.mean(axis=0)\n",
    "                s = X.std(axis=0)\n",
    "                s[s < 1e-10] = 1.0\n",
    "                return (X - m) / s\n",
    "\n",
    "            rwse_norm = normalize(rwse[:n_compare])\n",
    "            srwe_norm = normalize(srwe_feats[:n_compare])\n",
    "\n",
    "            node_sris = sm.get(\"node_sris\", [])\n",
    "\n",
    "            lappe_feats = compute_lappe_features(\n",
    "                local_spectral[:n_compare], eigenvalues, num_dims=min(10, len(eigenvalues))\n",
    "            )\n",
    "            lappe_norm = normalize(lappe_feats[:n_compare])\n",
    "\n",
    "            n_pairs_check = min(50, n_compare * (n_compare - 1) // 2)\n",
    "            for _ in range(n_pairs_check):\n",
    "                u = rng.randint(0, n_compare - 1)\n",
    "                w = rng.randint(u + 1, n_compare)\n",
    "\n",
    "                rwse_dist = np.linalg.norm(rwse_norm[u] - rwse_norm[w])\n",
    "                srwe_dist = np.linalg.norm(srwe_norm[u] - srwe_norm[w])\n",
    "                lappe_dist = np.linalg.norm(lappe_norm[u] - lappe_norm[w]) if lappe_norm.shape[0] > w else 0.0\n",
    "\n",
    "                super_dist = max(srwe_dist, lappe_dist)\n",
    "\n",
    "                pair_sri = min(\n",
    "                    node_sris[u] if u < len(node_sris) and np.isfinite(node_sris[u]) else float(\"inf\"),\n",
    "                    node_sris[w] if w < len(node_sris) and np.isfinite(node_sris[w]) else float(\"inf\"),\n",
    "                )\n",
    "\n",
    "                if rwse_dist > EPSILON:\n",
    "                    srwe_node_sris_by_category[\"already_resolved\"].append(pair_sri)\n",
    "                elif super_dist > EPSILON:\n",
    "                    srwe_node_sris_by_category[\"newly_resolved\"].append(pair_sri)\n",
    "                else:\n",
    "                    srwe_node_sris_by_category[\"still_unresolved\"].append(pair_sri)\n",
    "\n",
    "            n_srwe_processed += 1\n",
    "        except Exception as e:\n",
    "            n_srwe_processed += 1\n",
    "            continue\n",
    "\n",
    "# Mann-Whitney U test\n",
    "newly = [v for v in srwe_node_sris_by_category[\"newly_resolved\"] if np.isfinite(v)]\n",
    "already = [v for v in srwe_node_sris_by_category[\"already_resolved\"] if np.isfinite(v)]\n",
    "unresolved = [v for v in srwe_node_sris_by_category[\"still_unresolved\"] if np.isfinite(v)]\n",
    "\n",
    "print(f\"  SRWE categories: already={len(already)}, newly={len(newly)}, unresolved={len(unresolved)}\")\n",
    "\n",
    "if len(newly) >= 3 and len(already) >= 3:\n",
    "    try:\n",
    "        u_stat, u_p = stats.mannwhitneyu(newly, already, alternative=\"less\")\n",
    "        print(f\"  Mann-Whitney U: newly vs already: U={u_stat:.1f}, p={u_p:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Mann-Whitney U test failed: {e}\")\n",
    "\n",
    "print(f\"\\nPhase 4 completed in {time.time() - start_time:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "w14yy19sa4",
   "metadata": {},
   "source": [
    "## Results Summary & Visualization\n",
    "\n",
    "Print key results as a table and generate figures showing the comparison between graph-level and node-level SRI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4oqzps8ybho",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T19:40:01.119317Z",
     "iopub.status.busy": "2026-02-22T19:40:01.119248Z",
     "iopub.status.idle": "2026-02-22T19:40:01.121986Z",
     "shell.execute_reply": "2026-02-22T19:40:01.121791Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "RESULTS SUMMARY: Graph-Level vs Node-Level SRI Correlations\n",
      "======================================================================\n",
      "Dataset              Metric               Spearman rho               95% CI    p-value\n",
      "----------------------------------------------------------------------------------\n",
      "ZINC-subset          graph_sri                  0.6350       [0.455, 0.772]     0.0000\n",
      "ZINC-subset          mean_node_sri              0.5105       [0.281, 0.684]     0.0002\n",
      "ZINC-subset          min_node_sri               0.6065       [0.419, 0.748]     0.0000\n",
      "ZINC-subset          median_node_sri            0.3776       [0.089, 0.608]     0.0069\n",
      "ZINC-subset          p10_node_sri               0.5074       [0.280, 0.686]     0.0002\n",
      "ZINC-subset          harmonic_node_sri          0.5097       [0.268, 0.690]     0.0002\n",
      "Pooled               graph_sri                  0.6350       [0.455, 0.772]     0.0000\n",
      "Pooled               mean_node_sri              0.5105       [0.281, 0.684]     0.0002\n",
      "\n",
      "SRWE Benefit Prediction:\n",
      "  Already resolved (RWSE):  n=2431, mean SRI=2.5269\n",
      "  Newly resolved (SRWE):    n=30, mean SRI=6.9164\n",
      "  Still unresolved:         n=39, mean SRI=2.8691\n",
      "\n",
      "Total pipeline runtime: 7.1s\n"
     ]
    }
   ],
   "source": [
    "# ── Results Summary Table ──\n",
    "print(\"=\" * 70)\n",
    "print(\"RESULTS SUMMARY: Graph-Level vs Node-Level SRI Correlations\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Dataset':<20} {'Metric':<20} {'Spearman rho':>12} {'95% CI':>20} {'p-value':>10}\")\n",
    "print(\"-\" * 82)\n",
    "\n",
    "for ds_name, ds_corr in correlation_results.items():\n",
    "    for metric_name in [\"graph_sri\", \"mean_node_sri\", \"min_node_sri\", \"median_node_sri\", \"p10_node_sri\", \"harmonic_node_sri\"]:\n",
    "        if metric_name not in ds_corr:\n",
    "            continue\n",
    "        mc = ds_corr[metric_name]\n",
    "        if isinstance(mc, dict) and \"rho\" in mc:\n",
    "            ci = f\"[{mc.get('ci_lower', 0):.3f}, {mc.get('ci_upper', 0):.3f}]\"\n",
    "            print(f\"{ds_name:<20} {metric_name:<20} {mc['rho']:>12.4f} {ci:>20} {mc.get('p_value', 1.0):>10.4f}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# SRWE Summary\n",
    "print(\"SRWE Benefit Prediction:\")\n",
    "print(f\"  Already resolved (RWSE):  n={len(already)}, mean SRI={np.mean(already):.4f}\" if already else \"  Already resolved: 0\")\n",
    "print(f\"  Newly resolved (SRWE):    n={len(newly)}, mean SRI={np.mean(newly):.4f}\" if newly else \"  Newly resolved: 0\")\n",
    "print(f\"  Still unresolved:         n={len(unresolved)}, mean SRI={np.mean(unresolved):.4f}\" if unresolved else \"  Still unresolved: 0\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\nTotal pipeline runtime: {total_time:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7hvp3xe634d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T19:40:01.122993Z",
     "iopub.status.busy": "2026-02-22T19:40:01.122926Z",
     "iopub.status.idle": "2026-02-22T19:40:01.366050Z",
     "shell.execute_reply": "2026-02-22T19:40:01.365560Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization saved to results_visualization.png\n"
     ]
    }
   ],
   "source": [
    "# ── Visualization ──\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Plot 1: Correlation comparison bar chart\n",
    "ax = axes[0]\n",
    "for ds_name, ds_corr in correlation_results.items():\n",
    "    labels = []\n",
    "    rhos = []\n",
    "    for mn in [\"graph_sri\", \"mean_node_sri\", \"min_node_sri\"]:\n",
    "        if mn in ds_corr and isinstance(ds_corr[mn], dict) and \"rho\" in ds_corr[mn]:\n",
    "            labels.append(mn.replace(\"_\", \"\\n\"))\n",
    "            rhos.append(abs(ds_corr[mn][\"rho\"]))\n",
    "    if labels:\n",
    "        x = np.arange(len(labels))\n",
    "        colors = [\"#2196F3\" if \"graph\" in l.lower() else \"#FF9800\" for l in labels]\n",
    "        ax.bar(x, rhos, color=colors, alpha=0.8)\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(labels, fontsize=8)\n",
    "        ax.set_title(f\"SRI Correlations ({ds_name})\")\n",
    "        ax.set_ylabel(\"|Spearman rho|\")\n",
    "        ax.set_ylim(0, 1.0)\n",
    "        ax.axhline(y=0.3, color=\"red\", linestyle=\"--\", alpha=0.5, label=\"rho=0.3\")\n",
    "        ax.legend(fontsize=7)\n",
    "\n",
    "# Plot 2: Graph SRI vs Mean Node SRI scatter\n",
    "ax = axes[1]\n",
    "for ds_name, sampled in all_sampled_metrics.items():\n",
    "    gs = [s[\"graph_sri\"] for s in sampled]\n",
    "    mns = [s[\"mean_node_sri\"] for s in sampled]\n",
    "    finite = [np.isfinite(g) and np.isfinite(m) for g, m in zip(gs, mns)]\n",
    "    gs_f = [g for g, f in zip(gs, finite) if f]\n",
    "    mns_f = [m for m, f in zip(mns, finite) if f]\n",
    "    if gs_f:\n",
    "        ax.scatter(gs_f, mns_f, alpha=0.6, s=20, label=ds_name)\n",
    "ax.set_xlabel(\"Graph-Level SRI\")\n",
    "ax.set_ylabel(\"Mean Node-Level SRI\")\n",
    "ax.set_title(\"Graph SRI vs Mean Node SRI\")\n",
    "ax.legend(fontsize=7)\n",
    "\n",
    "# Plot 3: Node SRI distribution for example graphs\n",
    "ax = axes[2]\n",
    "if example_graphs:\n",
    "    for i, eg in enumerate(example_graphs[:4]):\n",
    "        node_sris = eg.get(\"node_sris\", [])\n",
    "        finite_sris = [s if np.isfinite(s) else 0 for s in node_sris[:30]]\n",
    "        if finite_sris:\n",
    "            ax.bar(np.arange(len(finite_sris)) + i * 0.2,\n",
    "                   finite_sris, width=0.2, alpha=0.7,\n",
    "                   label=f\"{eg.get('gap_type', '')} (n={eg.get('n_nodes', '?')})\")\n",
    "    ax.set_xlabel(\"Node Index\")\n",
    "    ax.set_ylabel(\"Node SRI\")\n",
    "    ax.set_title(\"Node SRI Distribution (Example Graphs)\")\n",
    "    ax.legend(fontsize=7)\n",
    "else:\n",
    "    ax.text(0.5, 0.5, \"No example graphs available\", ha=\"center\", va=\"center\", transform=ax.transAxes)\n",
    "    ax.set_title(\"Node SRI Distribution\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"results_visualization.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(\"Visualization saved to results_visualization.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
