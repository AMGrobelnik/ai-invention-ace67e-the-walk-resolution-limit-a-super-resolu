{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9vgjr2455ui",
   "metadata": {},
   "source": [
    "# Grand Synthesis: Walk Resolution Limit Hypothesis Adjudication\n",
    "\n",
    "**Definitive meta-analytic synthesis** across all 10 experiment artifacts (5 iterations), formally adjudicating each of the 6 hypothesis success/disconfirmation criteria with quantified evidence.\n",
    "\n",
    "This notebook:\n",
    "- Computes **Fisher z random-effects meta-analysis** of 26 SRI-gap correlation studies\n",
    "- Formally **adjudicates 6 criteria** (C1–C3 confirmation, D1–D3 disconfirmation)\n",
    "- Builds **SRWE win/loss/tie scorecard** across encoding comparisons\n",
    "- Tests **moderator effects** (architecture, domain, metric type)\n",
    "- Produces **scope-of-validity map** and practical encoding selection guidelines\n",
    "- Generates **publication-quality figures** (forest plot, verdict dashboard, decision tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "yike1jfgcp",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T19:32:46.896607Z",
     "iopub.status.busy": "2026-02-22T19:32:46.896268Z",
     "iopub.status.idle": "2026-02-22T19:33:26.057374Z",
     "shell.execute_reply": "2026-02-22T19:33:26.057089Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import subprocess, sys\n",
    "def _pip(*a): subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', *a])\n",
    "\n",
    "# Core packages (pre-installed on Colab, install locally to match Colab env)\n",
    "if 'google.colab' not in sys.modules:\n",
    "    _pip('numpy==2.0.2', 'scipy==1.16.3', 'matplotlib==3.10.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0zdqga14kcxd",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "vvrh83e3779",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T19:33:26.058351Z",
     "iopub.status.busy": "2026-02-22T19:33:26.058274Z",
     "iopub.status.idle": "2026-02-22T19:33:26.587915Z",
     "shell.execute_reply": "2026-02-22T19:33:26.587492Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "from typing import Any\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2rx4l6mu9kd",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hsjhfblwqyf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T19:33:26.588862Z",
     "iopub.status.busy": "2026-02-22T19:33:26.588726Z",
     "iopub.status.idle": "2026-02-22T19:33:26.590835Z",
     "shell.execute_reply": "2026-02-22T19:33:26.590610Z"
    }
   },
   "outputs": [],
   "source": [
    "GITHUB_DATA_URL = \"https://raw.githubusercontent.com/AMGrobelnik/ai-invention-ace67e-the-walk-resolution-limit-a-super-resolu/main/evaluation_iter6_grand_synthesis/demo/mini_demo_data.json\"\n",
    "import json, os\n",
    "\n",
    "def load_data():\n",
    "    try:\n",
    "        import urllib.request\n",
    "        with urllib.request.urlopen(GITHUB_DATA_URL) as response:\n",
    "            return json.loads(response.read().decode())\n",
    "    except Exception: pass\n",
    "    if os.path.exists(\"mini_demo_data.json\"):\n",
    "        with open(\"mini_demo_data.json\") as f: return json.load(f)\n",
    "    raise FileNotFoundError(\"Could not load mini_demo_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "rdohaxmmfvh",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T19:33:26.591830Z",
     "iopub.status.busy": "2026-02-22T19:33:26.591744Z",
     "iopub.status.idle": "2026-02-22T19:33:26.772788Z",
     "shell.execute_reply": "2026-02-22T19:33:26.772315Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 26 SRI-gap correlation studies\n",
      "Loaded 18 scorecard entries\n",
      "Loaded 11 gap reduction conditions\n",
      "Loaded 9 SRWE performance results\n"
     ]
    }
   ],
   "source": [
    "data = load_data()\n",
    "studies = data[\"studies\"]\n",
    "scorecard = data[\"scorecard\"]\n",
    "gap_reductions = data[\"gap_reductions\"]\n",
    "srwe_results = data[\"srwe_results\"]\n",
    "c2_evidence = data[\"c2_evidence\"]\n",
    "within_corrs = data[\"within_corrs\"]\n",
    "weights = data[\"weights\"]\n",
    "\n",
    "print(f\"Loaded {len(studies)} SRI-gap correlation studies\")\n",
    "print(f\"Loaded {len(scorecard)} scorecard entries\")\n",
    "print(f\"Loaded {len(gap_reductions)} gap reduction conditions\")\n",
    "print(f\"Loaded {len(srwe_results)} SRWE performance results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3jj6jll82n5",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Hypothesis criteria weights and thresholds for adjudication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "vx73dh7evxi",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T19:33:26.773827Z",
     "iopub.status.busy": "2026-02-22T19:33:26.773756Z",
     "iopub.status.idle": "2026-02-22T19:33:26.776432Z",
     "shell.execute_reply": "2026-02-22T19:33:26.776033Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: C1=0.35, C2=0.2, C3=0.25, D1=0.1, D2=0.05, D3=0.05\n",
      "Thresholds: C1=0.5, D1=0.2\n"
     ]
    }
   ],
   "source": [
    "# ── Hypothesis criteria weights ──\n",
    "C1_WEIGHT = weights[\"C1_WEIGHT\"]  # 0.35 — SRI-gap correlation ρ > 0.5\n",
    "C2_WEIGHT = weights[\"C2_WEIGHT\"]  # 0.20 — Aliased pairs distinguishability\n",
    "C3_WEIGHT = weights[\"C3_WEIGHT\"]  # 0.25 — SRWE ≥50% gap reduction\n",
    "D1_WEIGHT = weights[\"D1_WEIGHT\"]  # 0.10 — ρ < 0.2 (disconfirmation)\n",
    "D2_WEIGHT = weights[\"D2_WEIGHT\"]  # 0.05 — Resolution mismatch\n",
    "D3_WEIGHT = weights[\"D3_WEIGHT\"]  # 0.05 — No SRWE improvement\n",
    "\n",
    "# ── Thresholds ──\n",
    "C1_RHO_THRESHOLD = 0.5    # Confirmation: ρ must exceed this\n",
    "D1_RHO_THRESHOLD = 0.2    # Disconfirmation: ρ below this\n",
    "TIE_THRESHOLD = 0.02      # Relative threshold for win/loss/tie\n",
    "BONFERRONI_ALPHA = 0.0083  # Bonferroni-corrected significance level\n",
    "\n",
    "# ── Figure settings ──\n",
    "FIGURE_DPI = 150\n",
    "MAX_SCORECARD_ROWS = 20  # Max rows in scorecard heatmap\n",
    "MAX_BAR_CHART_DATASETS = 3  # Max datasets in encoding bar chart\n",
    "\n",
    "print(f\"Weights: C1={C1_WEIGHT}, C2={C2_WEIGHT}, C3={C3_WEIGHT}, D1={D1_WEIGHT}, D2={D2_WEIGHT}, D3={D3_WEIGHT}\")\n",
    "print(f\"Thresholds: C1={C1_RHO_THRESHOLD}, D1={D1_RHO_THRESHOLD}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2uqnmlqyzcx",
   "metadata": {},
   "source": [
    "## 1. Fisher z Random-Effects Meta-Analysis\n",
    "\n",
    "Pools SRI-gap correlations across all experiments using Fisher z transformation with DerSimonian-Laird random-effects weighting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "av8tqsy703g",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T19:33:26.777597Z",
     "iopub.status.busy": "2026-02-22T19:33:26.777528Z",
     "iopub.status.idle": "2026-02-22T19:33:26.782766Z",
     "shell.execute_reply": "2026-02-22T19:33:26.782305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled ρ = 0.1526 [0.0204, 0.2796]\n",
      "I² = 99.0%, Q p-value = 0.0000\n",
      "Number of studies: 26\n"
     ]
    }
   ],
   "source": [
    "def fisher_z_meta_analysis(studies: list[dict]) -> dict:\n",
    "    \"\"\"Compute random-effects meta-analysis via Fisher z transformation.\"\"\"\n",
    "    if not studies:\n",
    "        return {\"rho_pooled\": 0, \"ci_low\": 0, \"ci_high\": 0, \"I2\": 0, \"Q_pvalue\": 1.0, \"k\": 0}\n",
    "\n",
    "    rhos = np.array([s[\"rho\"] for s in studies])\n",
    "    ns = np.array([s[\"n\"] for s in studies])\n",
    "\n",
    "    # Fisher z transformation\n",
    "    # Clip rhos to avoid arctanh(±1)\n",
    "    rhos_clipped = np.clip(rhos, -0.999, 0.999)\n",
    "    zs = np.arctanh(rhos_clipped)\n",
    "    vs = 1.0 / (ns - 3.0)  # Variance of Fisher z\n",
    "    ws = 1.0 / vs  # Fixed-effect weights\n",
    "\n",
    "    k = len(studies)\n",
    "\n",
    "    # Fixed-effect pooled estimate\n",
    "    z_fe = np.sum(ws * zs) / np.sum(ws)\n",
    "\n",
    "    # Cochran's Q\n",
    "    Q = np.sum(ws * (zs - z_fe) ** 2)\n",
    "    df = k - 1\n",
    "    Q_pvalue = 1.0 - stats.chi2.cdf(Q, df) if df > 0 else 1.0\n",
    "\n",
    "    # DerSimonian-Laird tau^2\n",
    "    C = np.sum(ws) - np.sum(ws**2) / np.sum(ws)\n",
    "    tau2 = max(0, (Q - df) / C) if C > 0 else 0\n",
    "\n",
    "    # Random-effects weights\n",
    "    ws_re = 1.0 / (vs + tau2)\n",
    "    z_re = np.sum(ws_re * zs) / np.sum(ws_re)\n",
    "    se_re = 1.0 / np.sqrt(np.sum(ws_re))\n",
    "\n",
    "    # Back-transform\n",
    "    rho_pooled = np.tanh(z_re)\n",
    "    ci_low = np.tanh(z_re - 1.96 * se_re)\n",
    "    ci_high = np.tanh(z_re + 1.96 * se_re)\n",
    "\n",
    "    # I² heterogeneity\n",
    "    I2 = max(0, (Q - df) / Q * 100) if Q > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"rho_pooled\": float(rho_pooled),\n",
    "        \"ci_low\": float(ci_low),\n",
    "        \"ci_high\": float(ci_high),\n",
    "        \"I2\": float(I2),\n",
    "        \"Q\": float(Q),\n",
    "        \"Q_pvalue\": float(Q_pvalue),\n",
    "        \"tau2\": float(tau2),\n",
    "        \"k\": k,\n",
    "    }\n",
    "\n",
    "# Run meta-analysis\n",
    "pooled = fisher_z_meta_analysis(studies)\n",
    "print(f\"Pooled ρ = {pooled['rho_pooled']:.4f} [{pooled['ci_low']:.4f}, {pooled['ci_high']:.4f}]\")\n",
    "print(f\"I² = {pooled['I2']:.1f}%, Q p-value = {pooled['Q_pvalue']:.4f}\")\n",
    "print(f\"Number of studies: {pooled['k']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0n8whvwoasjm",
   "metadata": {},
   "source": [
    "## 2. Subgroup Meta-Analysis\n",
    "\n",
    "Breaks down the pooled correlation by dataset domain, architecture type, and metric type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "j4ajb3g7cs",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T19:33:26.783936Z",
     "iopub.status.busy": "2026-02-22T19:33:26.783849Z",
     "iopub.status.idle": "2026-02-22T19:33:26.788269Z",
     "shell.execute_reply": "2026-02-22T19:33:26.787954Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "by_domain:\n",
      "  molecular: ρ=0.0826 [0.0044, 0.1598], k=9\n",
      "  protein: ρ=0.1742 [-0.0909, 0.4164], k=13\n",
      "  synthetic: ρ=0.2734 [-0.3022, 0.7029], k=3\n",
      "\n",
      "by_architecture:\n",
      "  model: ρ=0.5600 [0.2075, 0.7838], k=5\n",
      "  MLP: ρ=0.0207 [-0.0774, 0.1183], k=4\n",
      "  GPS: ρ=-0.0302 [-0.1212, 0.0614], k=7\n",
      "  GCN: ρ=0.1003 [0.0710, 0.1295], k=10\n",
      "\n",
      "by_metric_type:\n",
      "  node_distinguishability: ρ=0.5600 [0.2075, 0.7838], k=5\n",
      "  task_performance: ρ=0.0480 [0.0106, 0.0852], k=21\n"
     ]
    }
   ],
   "source": [
    "def subgroup_meta_analysis(studies: list[dict]) -> dict:\n",
    "    \"\"\"Compute subgroup meta-analyses by dataset domain, architecture, metric type.\"\"\"\n",
    "    results = {}\n",
    "\n",
    "    # By dataset domain\n",
    "    domain_map = {\n",
    "        \"ZINC-subset\": \"molecular\", \"zinc\": \"molecular\",\n",
    "        \"Peptides-func\": \"protein\", \"peptides_func\": \"protein\",\n",
    "        \"Peptides-struct\": \"protein\", \"peptides_struct\": \"protein\",\n",
    "        \"Synthetic-aliased-pairs\": \"synthetic\", \"synthetic_fixed_n30\": \"synthetic\",\n",
    "        \"Multi-dataset\": \"mixed\",\n",
    "    }\n",
    "\n",
    "    by_domain = {}\n",
    "    for s in studies:\n",
    "        domain = domain_map.get(s[\"dataset\"], \"other\")\n",
    "        by_domain.setdefault(domain, []).append(s)\n",
    "\n",
    "    results[\"by_domain\"] = {}\n",
    "    for domain, domain_studies in by_domain.items():\n",
    "        if len(domain_studies) >= 2:\n",
    "            results[\"by_domain\"][domain] = fisher_z_meta_analysis(domain_studies)\n",
    "\n",
    "    # By architecture\n",
    "    by_arch = {}\n",
    "    for s in studies:\n",
    "        arch = s[\"architecture\"].split(\"_\")[0]  # Normalize\n",
    "        by_arch.setdefault(arch, []).append(s)\n",
    "\n",
    "    results[\"by_architecture\"] = {}\n",
    "    for arch, arch_studies in by_arch.items():\n",
    "        if len(arch_studies) >= 2:\n",
    "            results[\"by_architecture\"][arch] = fisher_z_meta_analysis(arch_studies)\n",
    "\n",
    "    # By metric type\n",
    "    by_metric = {}\n",
    "    for s in studies:\n",
    "        by_metric.setdefault(s[\"metric_type\"], []).append(s)\n",
    "\n",
    "    results[\"by_metric_type\"] = {}\n",
    "    for mt, mt_studies in by_metric.items():\n",
    "        if len(mt_studies) >= 2:\n",
    "            results[\"by_metric_type\"][mt] = fisher_z_meta_analysis(mt_studies)\n",
    "\n",
    "    return results\n",
    "\n",
    "subgroup = subgroup_meta_analysis(studies)\n",
    "for category, sub_results in subgroup.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for name, res in sub_results.items():\n",
    "        print(f\"  {name}: ρ={res['rho_pooled']:.4f} [{res['ci_low']:.4f}, {res['ci_high']:.4f}], k={res['k']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ck9szgoor7t",
   "metadata": {},
   "source": [
    "## 3. Moderator Analysis\n",
    "\n",
    "Tests whether dataset domain, architecture type, or metric type significantly moderate the SRI-gap correlation using Kruskal-Wallis and Mann-Whitney U tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7uboodwv5ei",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T19:33:26.789499Z",
     "iopub.status.busy": "2026-02-22T19:33:26.789427Z",
     "iopub.status.idle": "2026-02-22T19:33:26.795945Z",
     "shell.execute_reply": "2026-02-22T19:33:26.795589Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  dataset_domain: p=0.8189 (not significant)\n",
      "  architecture: p=0.0010 (SIGNIFICANT)\n",
      "  metric_type: p=0.0009 (SIGNIFICANT)\n"
     ]
    }
   ],
   "source": [
    "def compute_moderator_effects(studies: list[dict]) -> dict:\n",
    "    \"\"\"Analyze moderator effects on SRI-gap correlation.\"\"\"\n",
    "    moderators = {}\n",
    "\n",
    "    # 1. Dataset domain\n",
    "    domain_map = {\n",
    "        \"ZINC-subset\": \"molecular\", \"zinc\": \"molecular\",\n",
    "        \"Peptides-func\": \"protein\", \"peptides_func\": \"protein\",\n",
    "        \"Peptides-struct\": \"protein\", \"peptides_struct\": \"protein\",\n",
    "        \"Synthetic-aliased-pairs\": \"synthetic\", \"synthetic_fixed_n30\": \"synthetic\",\n",
    "    }\n",
    "\n",
    "    domains = [domain_map.get(s[\"dataset\"], \"other\") for s in studies]\n",
    "    rhos = [s[\"rho\"] for s in studies]\n",
    "\n",
    "    if len(set(domains)) >= 2:\n",
    "        domain_groups = {}\n",
    "        for d, r in zip(domains, rhos):\n",
    "            domain_groups.setdefault(d, []).append(r)\n",
    "\n",
    "        groups = [np.array(v) for v in domain_groups.values() if len(v) >= 2]\n",
    "        if len(groups) >= 2:\n",
    "            try:\n",
    "                h_stat, kw_p = stats.kruskal(*groups)\n",
    "                n_total = sum(len(g) for g in groups)\n",
    "                eta2 = (h_stat - len(groups) + 1) / (n_total - len(groups)) if n_total > len(groups) else 0\n",
    "                moderators[\"dataset_domain\"] = {\n",
    "                    \"H_statistic\": float(h_stat),\n",
    "                    \"p_value\": float(kw_p),\n",
    "                    \"eta_squared\": float(max(0, eta2)),\n",
    "                    \"n_groups\": len(groups),\n",
    "                    \"significant\": kw_p < BONFERRONI_ALPHA,\n",
    "                }\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    # 2. Architecture type\n",
    "    archs = [s[\"architecture\"].split(\"_\")[0] for s in studies]\n",
    "    if len(set(archs)) >= 2:\n",
    "        arch_groups = {}\n",
    "        for a, r in zip(archs, rhos):\n",
    "            arch_groups.setdefault(a, []).append(r)\n",
    "        groups = [np.array(v) for v in arch_groups.values() if len(v) >= 2]\n",
    "        if len(groups) >= 2:\n",
    "            try:\n",
    "                h_stat, kw_p = stats.kruskal(*groups)\n",
    "                n_total = sum(len(g) for g in groups)\n",
    "                eta2 = (h_stat - len(groups) + 1) / (n_total - len(groups)) if n_total > len(groups) else 0\n",
    "                moderators[\"architecture\"] = {\n",
    "                    \"H_statistic\": float(h_stat),\n",
    "                    \"p_value\": float(kw_p),\n",
    "                    \"eta_squared\": float(max(0, eta2)),\n",
    "                    \"n_groups\": len(groups),\n",
    "                    \"significant\": kw_p < BONFERRONI_ALPHA,\n",
    "                }\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    # 3. Metric type (node distinguishability vs task performance)\n",
    "    metric_groups = {}\n",
    "    for s in studies:\n",
    "        metric_groups.setdefault(s[\"metric_type\"], []).append(s[\"rho\"])\n",
    "    if len(metric_groups) >= 2:\n",
    "        groups = [np.array(v) for v in metric_groups.values() if len(v) >= 2]\n",
    "        if len(groups) >= 2:\n",
    "            try:\n",
    "                t_stat, mw_p = stats.mannwhitneyu(groups[0], groups[1], alternative=\"two-sided\")\n",
    "                moderators[\"metric_type\"] = {\n",
    "                    \"U_statistic\": float(t_stat),\n",
    "                    \"p_value\": float(mw_p),\n",
    "                    \"significant\": mw_p < BONFERRONI_ALPHA,\n",
    "                }\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    return moderators\n",
    "\n",
    "moderators = compute_moderator_effects(studies)\n",
    "for mod_name, mod_data in moderators.items():\n",
    "    sig_str = \"SIGNIFICANT\" if mod_data.get(\"significant\") else \"not significant\"\n",
    "    print(f\"  {mod_name}: p={mod_data['p_value']:.4f} ({sig_str})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p8ttl1mthuj",
   "metadata": {},
   "source": [
    "## 4. Criterion Adjudication\n",
    "\n",
    "Formally adjudicates all 6 hypothesis criteria (C1-C3 confirmation, D1-D3 disconfirmation) and computes weighted overall verdict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "v4cxyipvc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T19:33:26.796997Z",
     "iopub.status.busy": "2026-02-22T19:33:26.796916Z",
     "iopub.status.idle": "2026-02-22T19:33:26.805848Z",
     "shell.execute_reply": "2026-02-22T19:33:26.805487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall verdict: partially_confirmed (score=0.458)\n",
      "Confirmation score: 0.224\n",
      "Disconfirmation penalty: 0.003\n",
      "\n",
      "  C1_sri_gap_correlation: not_confirmed (conf=0.86)\n",
      "  C2_aliased_pairs_distinguishability: confirmed (conf=0.67)\n",
      "  C3_srwe_gap_reduction: partially_confirmed (conf=0.36)\n",
      "  D1_weak_correlation: disconfirmed (conf=0.24)\n",
      "  D2_resolution_mismatch: not_confirmed (conf=0.50)\n",
      "  D3_no_srwe_improvement: partially_confirmed (conf=0.50)\n"
     ]
    }
   ],
   "source": [
    "def adjudicate_criteria(pooled: dict, studies: list[dict],\n",
    "                        gap_reductions: dict, scorecard: dict,\n",
    "                        c2_evidence: list, within_corrs: list) -> dict:\n",
    "    \"\"\"Formally adjudicate all 6 hypothesis criteria.\"\"\"\n",
    "    verdicts = {}\n",
    "\n",
    "    # ── C1: ρ > 0.5 (Confirmation Criterion 1) ──\n",
    "    rho = pooled[\"rho_pooled\"]\n",
    "    ci_low = pooled[\"ci_low\"]\n",
    "    if rho > C1_RHO_THRESHOLD:\n",
    "        c1_verdict = \"confirmed\"\n",
    "        c1_confidence = min(1.0, (rho - 0.5) / 0.3 + 0.5)\n",
    "    elif rho > 0.35:\n",
    "        c1_verdict = \"partially_confirmed\"\n",
    "        c1_confidence = (rho - 0.2) / 0.3\n",
    "    elif rho > D1_RHO_THRESHOLD:\n",
    "        c1_verdict = \"partially_confirmed\"\n",
    "        c1_confidence = (rho - 0.2) / 0.3\n",
    "    else:\n",
    "        c1_verdict = \"not_confirmed\"\n",
    "        c1_confidence = max(0, rho / 0.2)\n",
    "\n",
    "    if ci_low > 0:\n",
    "        c1_confidence = min(1.0, c1_confidence + 0.1)\n",
    "    if ci_low < 0:\n",
    "        c1_confidence = max(0, c1_confidence - 0.2)\n",
    "\n",
    "    verdicts[\"C1_sri_gap_correlation\"] = {\n",
    "        \"criterion\": \"Spearman rho(SRI, RWSE-LapPE gap) > 0.5\",\n",
    "        \"verdict\": c1_verdict,\n",
    "        \"confidence\": round(float(c1_confidence), 3),\n",
    "        \"evidence\": f\"Pooled rho = {rho:.3f}, 95% CI [{ci_low:.3f}, {pooled['ci_high']:.3f}], I2 = {pooled['I2']:.1f}%\",\n",
    "    }\n",
    "\n",
    "    # ── C2: Aliased pairs distinguishability ──\n",
    "    if c2_evidence:\n",
    "        mean_distinguish = np.mean(c2_evidence)\n",
    "        if mean_distinguish > 75:\n",
    "            c2_verdict = \"confirmed\"\n",
    "            c2_confidence = min(1.0, (mean_distinguish - 50) / 50)\n",
    "        elif mean_distinguish > 50:\n",
    "            c2_verdict = \"partially_confirmed\"\n",
    "            c2_confidence = (mean_distinguish - 50) / 50\n",
    "        else:\n",
    "            c2_verdict = \"not_confirmed\"\n",
    "            c2_confidence = mean_distinguish / 100\n",
    "    else:\n",
    "        c2_verdict = \"partially_confirmed\"\n",
    "        c2_confidence = 0.5\n",
    "        mean_distinguish = 0\n",
    "\n",
    "    verdicts[\"C2_aliased_pairs_distinguishability\"] = {\n",
    "        \"criterion\": \"SRWE better than RWSE at distinguishing aliased graph pairs\",\n",
    "        \"verdict\": c2_verdict,\n",
    "        \"confidence\": round(float(c2_confidence), 3),\n",
    "        \"evidence\": f\"Mean distinguishability: {mean_distinguish:.1f}% across {len(c2_evidence)} categories\",\n",
    "    }\n",
    "\n",
    "    # ── C3: SRWE >= 50% gap reduction ──\n",
    "    gap_red_values = []\n",
    "    for k, v in gap_reductions.items():\n",
    "        gr = v.get(\"gap_reduction_fraction\", None)\n",
    "        if gr is not None and not math.isnan(gr) and -5 < gr < 5:\n",
    "            gap_red_values.append(gr)\n",
    "\n",
    "    if gap_red_values:\n",
    "        mean_gap_red = np.mean(gap_red_values)\n",
    "        n_above_50 = sum(1 for g in gap_red_values if g >= 0.5)\n",
    "        frac_above_50 = n_above_50 / len(gap_red_values)\n",
    "        if frac_above_50 >= 0.5 and mean_gap_red >= 0.5:\n",
    "            c3_verdict = \"confirmed\"\n",
    "            c3_confidence = min(1.0, mean_gap_red)\n",
    "        elif frac_above_50 >= 0.25 or mean_gap_red >= 0.3:\n",
    "            c3_verdict = \"partially_confirmed\"\n",
    "            c3_confidence = max(frac_above_50, mean_gap_red)\n",
    "        else:\n",
    "            c3_verdict = \"not_confirmed\"\n",
    "            c3_confidence = max(0, mean_gap_red)\n",
    "    else:\n",
    "        c3_verdict = \"not_confirmed\"\n",
    "        c3_confidence = 0.0\n",
    "        mean_gap_red = 0\n",
    "        frac_above_50 = 0\n",
    "\n",
    "    verdicts[\"C3_srwe_gap_reduction\"] = {\n",
    "        \"criterion\": \"SRWE achieves >=50% gap reduction on low-SRI graphs\",\n",
    "        \"verdict\": c3_verdict,\n",
    "        \"confidence\": round(float(c3_confidence), 3),\n",
    "        \"evidence\": f\"Mean gap reduction: {mean_gap_red:.3f}, {frac_above_50*100:.0f}% conditions above 50%\",\n",
    "    }\n",
    "\n",
    "    # ── D1: ρ < 0.2 (Disconfirmation) ──\n",
    "    if rho < D1_RHO_THRESHOLD:\n",
    "        d1_verdict = \"disconfirmed\"\n",
    "        d1_confidence = 1.0 - rho / 0.2\n",
    "    elif rho < 0.35:\n",
    "        d1_verdict = \"partially_confirmed\"\n",
    "        d1_confidence = 0.5\n",
    "    else:\n",
    "        d1_verdict = \"not_confirmed\"\n",
    "        d1_confidence = max(0, 1.0 - (rho - 0.2) / 0.3)\n",
    "\n",
    "    verdicts[\"D1_weak_correlation\"] = {\n",
    "        \"criterion\": \"Spearman rho(SRI, gap) < 0.2 -> theory disconfirmed\",\n",
    "        \"verdict\": d1_verdict,\n",
    "        \"confidence\": round(float(d1_confidence), 3),\n",
    "        \"evidence\": f\"Pooled rho = {rho:.3f}\",\n",
    "    }\n",
    "\n",
    "    # ── D2: Resolution mismatch ──\n",
    "    if within_corrs:\n",
    "        mean_within = np.mean(np.abs(within_corrs))\n",
    "        d2_verdict = \"not_confirmed\" if mean_within > 0.05 else \"disconfirmed\"\n",
    "        d2_confidence = 0.5\n",
    "    else:\n",
    "        d2_verdict = \"not_confirmed\"\n",
    "        d2_confidence = 0.3\n",
    "        mean_within = 0\n",
    "\n",
    "    verdicts[\"D2_resolution_mismatch\"] = {\n",
    "        \"criterion\": \"SRI correlation disappears when controlling for graph size\",\n",
    "        \"verdict\": d2_verdict,\n",
    "        \"confidence\": round(float(d2_confidence), 3),\n",
    "        \"evidence\": f\"Mean within-size-bin |rho| = {mean_within:.3f}\",\n",
    "    }\n",
    "\n",
    "    # ── D3: No SRWE improvement ──\n",
    "    total_wins = 0\n",
    "    total_losses = 0\n",
    "    for key, sc in scorecard.items():\n",
    "        if \"srwe\" in key.lower() and \"rwse\" in key.lower():\n",
    "            total_wins += sc[\"wins\"]\n",
    "            total_losses += sc[\"losses\"]\n",
    "\n",
    "    if total_wins + total_losses > 0:\n",
    "        win_rate = total_wins / (total_wins + total_losses)\n",
    "        if win_rate < 0.3:\n",
    "            d3_verdict = \"disconfirmed\"\n",
    "            d3_confidence = 1.0 - win_rate\n",
    "        elif win_rate < 0.5:\n",
    "            d3_verdict = \"partially_confirmed\"\n",
    "            d3_confidence = 0.5\n",
    "        else:\n",
    "            d3_verdict = \"not_confirmed\"\n",
    "            d3_confidence = win_rate\n",
    "    else:\n",
    "        d3_verdict = \"not_confirmed\"\n",
    "        d3_confidence = 0.3\n",
    "        win_rate = 0.5\n",
    "\n",
    "    verdicts[\"D3_no_srwe_improvement\"] = {\n",
    "        \"criterion\": \"SRWE shows no systematic improvement over RWSE\",\n",
    "        \"verdict\": d3_verdict,\n",
    "        \"confidence\": round(float(d3_confidence), 3),\n",
    "        \"evidence\": f\"SRWE vs RWSE win rate: {win_rate:.1%} ({total_wins}W/{total_losses}L)\",\n",
    "    }\n",
    "\n",
    "    return verdicts\n",
    "\n",
    "\n",
    "def compute_overall_verdict(verdicts: dict) -> dict:\n",
    "    \"\"\"Compute weighted overall hypothesis verdict.\"\"\"\n",
    "    score_map = {\n",
    "        \"confirmed\": 1.0,\n",
    "        \"partially_confirmed\": 0.5,\n",
    "        \"not_confirmed\": 0.0,\n",
    "        \"disconfirmed\": -0.5,\n",
    "    }\n",
    "\n",
    "    c1_score = score_map.get(verdicts[\"C1_sri_gap_correlation\"][\"verdict\"], 0) * verdicts[\"C1_sri_gap_correlation\"][\"confidence\"]\n",
    "    c2_score = score_map.get(verdicts[\"C2_aliased_pairs_distinguishability\"][\"verdict\"], 0) * verdicts[\"C2_aliased_pairs_distinguishability\"][\"confidence\"]\n",
    "    c3_score = score_map.get(verdicts[\"C3_srwe_gap_reduction\"][\"verdict\"], 0) * verdicts[\"C3_srwe_gap_reduction\"][\"confidence\"]\n",
    "\n",
    "    d1_score = score_map.get(verdicts[\"D1_weak_correlation\"][\"verdict\"], 0) * verdicts[\"D1_weak_correlation\"][\"confidence\"]\n",
    "    d2_score = score_map.get(verdicts[\"D2_resolution_mismatch\"][\"verdict\"], 0) * verdicts[\"D2_resolution_mismatch\"][\"confidence\"]\n",
    "    d3_score = score_map.get(verdicts[\"D3_no_srwe_improvement\"][\"verdict\"], 0) * verdicts[\"D3_no_srwe_improvement\"][\"confidence\"]\n",
    "\n",
    "    confirmation_score = (C1_WEIGHT * c1_score + C2_WEIGHT * c2_score + C3_WEIGHT * c3_score) / (C1_WEIGHT + C2_WEIGHT + C3_WEIGHT)\n",
    "    disconfirmation_penalty = (D1_WEIGHT * d1_score + D2_WEIGHT * d2_score + D3_WEIGHT * d3_score) / (D1_WEIGHT + D2_WEIGHT + D3_WEIGHT)\n",
    "\n",
    "    overall_score = confirmation_score * 0.7 + (1.0 + disconfirmation_penalty) * 0.3\n",
    "\n",
    "    if overall_score >= 0.6:\n",
    "        overall_verdict = \"confirmed\"\n",
    "    elif overall_score >= 0.4:\n",
    "        overall_verdict = \"partially_confirmed\"\n",
    "    elif overall_score >= 0.2:\n",
    "        overall_verdict = \"weakly_supported\"\n",
    "    else:\n",
    "        overall_verdict = \"not_confirmed\"\n",
    "\n",
    "    overall_confidence = min(1.0, max(0.0, overall_score))\n",
    "\n",
    "    return {\n",
    "        \"overall_verdict\": overall_verdict,\n",
    "        \"overall_confidence\": round(float(overall_confidence), 3),\n",
    "        \"overall_score\": round(float(overall_score), 3),\n",
    "        \"confirmation_score\": round(float(confirmation_score), 3),\n",
    "        \"disconfirmation_penalty\": round(float(disconfirmation_penalty), 3),\n",
    "    }\n",
    "\n",
    "# Run adjudication\n",
    "verdicts = adjudicate_criteria(pooled, studies, gap_reductions, scorecard, c2_evidence, within_corrs)\n",
    "overall = compute_overall_verdict(verdicts)\n",
    "\n",
    "print(f\"Overall verdict: {overall['overall_verdict']} (score={overall['overall_score']:.3f})\")\n",
    "print(f\"Confirmation score: {overall['confirmation_score']:.3f}\")\n",
    "print(f\"Disconfirmation penalty: {overall['disconfirmation_penalty']:.3f}\")\n",
    "print()\n",
    "for key, v in verdicts.items():\n",
    "    print(f\"  {key}: {v['verdict']} (conf={v['confidence']:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eppcd1n7ww8",
   "metadata": {},
   "source": [
    "## 5. Scope-of-Validity Analysis\n",
    "\n",
    "Classifies conditions where the WRL theory works vs. fails, and characterizes domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "w86vgxlewg",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T19:33:26.806718Z",
     "iopub.status.busy": "2026-02-22T19:33:26.806651Z",
     "iopub.status.idle": "2026-02-22T19:33:26.810094Z",
     "shell.execute_reply": "2026-02-22T19:33:26.809764Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theory directional accuracy: 19.2%\n",
      "Conditions where theory works: 5\n",
      "Conditions where theory fails: 21\n",
      "Domains where works: ['molecular', 'protein', 'synthetic']\n",
      "Domains where fails: ['molecular', 'other', 'protein', 'synthetic']\n"
     ]
    }
   ],
   "source": [
    "def compute_scope_of_validity(studies: list[dict]) -> dict:\n",
    "    \"\"\"Build scope-of-validity assessment.\"\"\"\n",
    "    theory_works = []\n",
    "    theory_fails = []\n",
    "\n",
    "    for s in studies:\n",
    "        works = abs(s[\"rho\"]) > D1_RHO_THRESHOLD and s[\"p_value\"] < 0.05\n",
    "        entry = {\n",
    "            \"dataset\": s[\"dataset\"],\n",
    "            \"architecture\": s[\"architecture\"],\n",
    "            \"rho\": s[\"rho\"],\n",
    "            \"p_value\": s[\"p_value\"],\n",
    "        }\n",
    "        if works:\n",
    "            theory_works.append(entry)\n",
    "        else:\n",
    "            theory_fails.append(entry)\n",
    "\n",
    "    total = len(theory_works) + len(theory_fails)\n",
    "    accuracy = len(theory_works) / total if total > 0 else 0\n",
    "\n",
    "    domain_map = {\n",
    "        \"ZINC-subset\": \"molecular\", \"zinc\": \"molecular\",\n",
    "        \"Peptides-func\": \"protein\", \"peptides_func\": \"protein\",\n",
    "        \"Peptides-struct\": \"protein\", \"peptides_struct\": \"protein\",\n",
    "        \"Synthetic-aliased-pairs\": \"synthetic\", \"synthetic_fixed_n30\": \"synthetic\",\n",
    "    }\n",
    "\n",
    "    works_domains = set()\n",
    "    fails_domains = set()\n",
    "    for w in theory_works:\n",
    "        works_domains.add(domain_map.get(w[\"dataset\"], \"other\"))\n",
    "    for f in theory_fails:\n",
    "        fails_domains.add(domain_map.get(f[\"dataset\"], \"other\"))\n",
    "\n",
    "    return {\n",
    "        \"n_conditions_works\": len(theory_works),\n",
    "        \"n_conditions_fails\": len(theory_fails),\n",
    "        \"directional_accuracy\": round(float(accuracy), 3),\n",
    "        \"domains_where_works\": sorted(works_domains),\n",
    "        \"domains_where_fails\": sorted(fails_domains),\n",
    "        \"works_conditions\": theory_works[:5],\n",
    "        \"fails_conditions\": theory_fails[:5],\n",
    "    }\n",
    "\n",
    "scope = compute_scope_of_validity(studies)\n",
    "print(f\"Theory directional accuracy: {scope['directional_accuracy']:.1%}\")\n",
    "print(f\"Conditions where theory works: {scope['n_conditions_works']}\")\n",
    "print(f\"Conditions where theory fails: {scope['n_conditions_fails']}\")\n",
    "print(f\"Domains where works: {scope['domains_where_works']}\")\n",
    "print(f\"Domains where fails: {scope['domains_where_fails']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9q1tf8zagq8",
   "metadata": {},
   "source": [
    "## 6. Figures\n",
    "\n",
    "Publication-quality visualizations: forest plot, verdict dashboard, SRWE scorecard, moderator ranking, scope-of-validity scatter, encoding selection decision tree, and encoding performance bars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4it7ys9cnjn",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T19:33:26.810889Z",
     "iopub.status.busy": "2026-02-22T19:33:26.810823Z",
     "iopub.status.idle": "2026-02-22T19:33:26.999277Z",
     "shell.execute_reply": "2026-02-22T19:33:26.998807Z"
    }
   },
   "outputs": [],
   "source": [
    "# ── Figure 1: Forest Plot ──\n",
    "def plot_forest(studies, pooled):\n",
    "    fig, ax = plt.subplots(figsize=(12, max(8, len(studies) * 0.35 + 2)))\n",
    "    y_positions = list(range(len(studies)))\n",
    "    labels, rhos, ci_lows, ci_highs = [], [], [], []\n",
    "\n",
    "    for s in studies:\n",
    "        n = s[\"n\"]\n",
    "        rho = s[\"rho\"]\n",
    "        se = 1.0 / max(np.sqrt(n - 3), 1)\n",
    "        z = np.arctanh(np.clip(rho, -0.999, 0.999))\n",
    "        ci_l = np.tanh(z - 1.96 * se)\n",
    "        ci_h = np.tanh(z + 1.96 * se)\n",
    "        rhos.append(rho)\n",
    "        ci_lows.append(ci_l)\n",
    "        ci_highs.append(ci_h)\n",
    "        labels.append(f\"{s['experiment']}|{s['dataset'][:15]}|{s['architecture'][:10]}\")\n",
    "\n",
    "    for i, (y, rho, cl, ch) in enumerate(zip(y_positions, rhos, ci_lows, ci_highs)):\n",
    "        ax.plot([cl, ch], [y, y], \"b-\", linewidth=1, alpha=0.7)\n",
    "        ax.plot(rho, y, \"bs\", markersize=5)\n",
    "\n",
    "    y_pooled = len(studies)\n",
    "    diamond_x = [pooled[\"ci_low\"], pooled[\"rho_pooled\"], pooled[\"ci_high\"], pooled[\"rho_pooled\"]]\n",
    "    diamond_y = [y_pooled, y_pooled + 0.3, y_pooled, y_pooled - 0.3]\n",
    "    ax.fill(diamond_x, diamond_y, color=\"red\", alpha=0.6)\n",
    "    labels.append(f\"POOLED (k={pooled['k']})\")\n",
    "\n",
    "    ax.set_yticks(list(range(len(labels))))\n",
    "    ax.set_yticklabels(labels, fontsize=7)\n",
    "    ax.axvline(0, color=\"gray\", linestyle=\"--\", alpha=0.5)\n",
    "    ax.axvline(C1_RHO_THRESHOLD, color=\"green\", linestyle=\":\", alpha=0.5, label=f\"C1 threshold (rho={C1_RHO_THRESHOLD})\")\n",
    "    ax.axvline(D1_RHO_THRESHOLD, color=\"orange\", linestyle=\":\", alpha=0.5, label=f\"D1 threshold (rho={D1_RHO_THRESHOLD})\")\n",
    "    ax.set_xlabel(\"Spearman rho (SRI vs RWSE-LapPE gap)\")\n",
    "    ax.set_title(\"Forest Plot: SRI-Gap Correlations Across All Experiments\")\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.set_xlim(-0.8, 1.0)\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(\"forest_plot.png\", dpi=FIGURE_DPI, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "plot_forest(studies, pooled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "uypnqwlvmvj",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T19:33:27.000335Z",
     "iopub.status.busy": "2026-02-22T19:33:27.000245Z",
     "iopub.status.idle": "2026-02-22T19:33:27.169937Z",
     "shell.execute_reply": "2026-02-22T19:33:27.169322Z"
    }
   },
   "outputs": [],
   "source": [
    "# ── Figure 2: Verdict Dashboard ──\n",
    "def plot_verdict_dashboard(verdicts, overall):\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(14, 8))\n",
    "    criteria = [\n",
    "        (\"C1_sri_gap_correlation\", \"C1: SRI-Gap rho > 0.5\"),\n",
    "        (\"C2_aliased_pairs_distinguishability\", \"C2: Aliased Distinguishability\"),\n",
    "        (\"C3_srwe_gap_reduction\", \"C3: SRWE Gap Reduction >=50%\"),\n",
    "        (\"D1_weak_correlation\", \"D1: Weak Correlation (rho < 0.2)\"),\n",
    "        (\"D2_resolution_mismatch\", \"D2: Resolution Mismatch\"),\n",
    "        (\"D3_no_srwe_improvement\", \"D3: No SRWE Improvement\"),\n",
    "    ]\n",
    "    color_map = {\n",
    "        \"confirmed\": \"#2ecc71\", \"partially_confirmed\": \"#f39c12\",\n",
    "        \"not_confirmed\": \"#e74c3c\", \"disconfirmed\": \"#8e44ad\",\n",
    "    }\n",
    "    for idx, (key, title) in enumerate(criteria):\n",
    "        ax = axes[idx // 3][idx % 3]\n",
    "        v = verdicts.get(key, {})\n",
    "        verdict = v.get(\"verdict\", \"not_confirmed\")\n",
    "        confidence = v.get(\"confidence\", 0)\n",
    "        color = color_map.get(verdict, \"#95a5a6\")\n",
    "        ax.barh([0], [confidence], color=color, height=0.5, alpha=0.8)\n",
    "        ax.set_xlim(0, 1.1)\n",
    "        ax.set_title(title, fontsize=9, fontweight=\"bold\")\n",
    "        ax.set_yticks([])\n",
    "        ax.text(confidence + 0.02, 0, f\"{verdict}\\n({confidence:.2f})\", va=\"center\", fontsize=8)\n",
    "\n",
    "    fig.suptitle(\n",
    "        f\"Walk Resolution Limit Hypothesis: {overall['overall_verdict'].upper()} \"\n",
    "        f\"(score={overall['overall_score']:.2f})\",\n",
    "        fontsize=13, fontweight=\"bold\",\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(\"verdict_dashboard.png\", dpi=FIGURE_DPI, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "plot_verdict_dashboard(verdicts, overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "wb883w7d8t7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T19:33:27.171307Z",
     "iopub.status.busy": "2026-02-22T19:33:27.171237Z",
     "iopub.status.idle": "2026-02-22T19:33:27.295699Z",
     "shell.execute_reply": "2026-02-22T19:33:27.295242Z"
    }
   },
   "outputs": [],
   "source": [
    "# ── Figure 3: SRWE Scorecard ──\n",
    "def plot_srwe_scorecard_heatmap(scorecard):\n",
    "    if not scorecard:\n",
    "        print(\"No scorecard data\")\n",
    "        return\n",
    "    keys = sorted(scorecard.keys())[:MAX_SCORECARD_ROWS]\n",
    "    data_arr = []\n",
    "    labels = []\n",
    "    for k in keys:\n",
    "        sc = scorecard[k]\n",
    "        win_rate = sc[\"wins\"] / max(sc[\"total\"], 1)\n",
    "        data_arr.append([sc[\"wins\"], sc[\"losses\"], sc[\"ties\"], win_rate])\n",
    "        labels.append(k.replace(\"_vs_\", \"\\nvs \"))\n",
    "\n",
    "    data_arr = np.array(data_arr)\n",
    "    fig, ax = plt.subplots(figsize=(10, max(6, len(labels) * 0.5)))\n",
    "    bar_height = 0.6\n",
    "    y_pos = np.arange(len(labels))\n",
    "    ax.barh(y_pos, data_arr[:, 0], bar_height, color=\"#2ecc71\", label=\"Wins\")\n",
    "    ax.barh(y_pos, data_arr[:, 1], bar_height, left=data_arr[:, 0], color=\"#e74c3c\", label=\"Losses\")\n",
    "    ax.barh(y_pos, data_arr[:, 2], bar_height, left=data_arr[:, 0] + data_arr[:, 1], color=\"#95a5a6\", label=\"Ties\")\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(labels, fontsize=7)\n",
    "    ax.set_xlabel(\"Count\")\n",
    "    ax.set_title(\"SRWE Win/Loss/Tie Scorecard\")\n",
    "    ax.legend(fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(\"srwe_scorecard.png\", dpi=FIGURE_DPI, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "plot_srwe_scorecard_heatmap(scorecard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "l72gt6n3ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T19:33:27.297011Z",
     "iopub.status.busy": "2026-02-22T19:33:27.296934Z",
     "iopub.status.idle": "2026-02-22T19:33:27.350435Z",
     "shell.execute_reply": "2026-02-22T19:33:27.349869Z"
    }
   },
   "outputs": [],
   "source": [
    "# ── Figure 4: Moderator Ranking ──\n",
    "def plot_moderator_ranking(moderators):\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    names, p_values = [], []\n",
    "    for mod_name, mod_data in moderators.items():\n",
    "        if isinstance(mod_data, dict) and \"p_value\" in mod_data:\n",
    "            names.append(mod_name)\n",
    "            p_values.append(mod_data[\"p_value\"])\n",
    "\n",
    "    if not names:\n",
    "        ax.text(0.5, 0.5, \"No moderator data\", ha=\"center\", va=\"center\")\n",
    "        plt.show()\n",
    "        plt.close(fig)\n",
    "        return\n",
    "\n",
    "    neg_log_p = [-np.log10(max(p, 1e-300)) for p in p_values]\n",
    "    sorted_idx = np.argsort(neg_log_p)[::-1]\n",
    "    y_pos = np.arange(len(names))\n",
    "    colors = [\"#e74c3c\" if p < BONFERRONI_ALPHA else \"#3498db\" for p in p_values]\n",
    "\n",
    "    ax.barh(y_pos, [neg_log_p[i] for i in sorted_idx], color=[colors[i] for i in sorted_idx])\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels([names[i] for i in sorted_idx])\n",
    "    ax.axvline(-np.log10(BONFERRONI_ALPHA), color=\"red\", linestyle=\"--\", label=f\"Bonferroni alpha={BONFERRONI_ALPHA}\")\n",
    "    ax.set_xlabel(\"-log10(p-value)\")\n",
    "    ax.set_title(\"Moderator Importance for SRI-Gap Correlation\")\n",
    "    ax.legend(fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(\"moderator_ranking.png\", dpi=FIGURE_DPI, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "plot_moderator_ranking(moderators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "brind8chw5s",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T19:33:27.351902Z",
     "iopub.status.busy": "2026-02-22T19:33:27.351775Z",
     "iopub.status.idle": "2026-02-22T19:33:27.461579Z",
     "shell.execute_reply": "2026-02-22T19:33:27.461130Z"
    }
   },
   "outputs": [],
   "source": [
    "# ── Figure 5: Scope-of-Validity Scatter ──\n",
    "def plot_scope_validity(studies):\n",
    "    fig, ax = plt.subplots(figsize=(10, 7))\n",
    "    domain_map = {\n",
    "        \"ZINC-subset\": \"molecular\", \"zinc\": \"molecular\",\n",
    "        \"Peptides-func\": \"protein\", \"peptides_func\": \"protein\",\n",
    "        \"Peptides-struct\": \"protein\", \"peptides_struct\": \"protein\",\n",
    "        \"Synthetic-aliased-pairs\": \"synthetic\", \"synthetic_fixed_n30\": \"synthetic\",\n",
    "    }\n",
    "    color_map = {\"molecular\": \"#3498db\", \"protein\": \"#2ecc71\", \"synthetic\": \"#e74c3c\", \"other\": \"#95a5a6\", \"mixed\": \"#9b59b6\"}\n",
    "    marker_map = {\"model\": \"o\", \"MLP\": \"s\", \"GPS\": \"D\", \"GCN\": \"^\"}\n",
    "\n",
    "    for s in studies:\n",
    "        domain = domain_map.get(s[\"dataset\"], \"other\")\n",
    "        arch = s[\"architecture\"].split(\"_\")[0]\n",
    "        color = color_map.get(domain, \"#95a5a6\")\n",
    "        marker = marker_map.get(arch, \"o\")\n",
    "        alpha = 0.8 if s[\"p_value\"] < 0.05 else 0.3\n",
    "        size = max(20, min(200, s[\"n\"] / 5))\n",
    "        ax.scatter(s[\"n\"], s[\"rho\"], c=color, marker=marker, s=size, alpha=alpha,\n",
    "                   edgecolors=\"black\" if s[\"p_value\"] < 0.05 else \"none\", linewidth=0.5)\n",
    "\n",
    "    ax.axhline(C1_RHO_THRESHOLD, color=\"green\", linestyle=\"--\", alpha=0.5, label=f\"C1 threshold (rho={C1_RHO_THRESHOLD})\")\n",
    "    ax.axhline(D1_RHO_THRESHOLD, color=\"orange\", linestyle=\"--\", alpha=0.5, label=f\"D1 threshold (rho={D1_RHO_THRESHOLD})\")\n",
    "    ax.axhline(0, color=\"gray\", linestyle=\"-\", alpha=0.3)\n",
    "\n",
    "    domain_patches = [mpatches.Patch(color=c, label=d) for d, c in color_map.items() if d != \"other\"]\n",
    "    ax.legend(handles=domain_patches, loc=\"upper left\", fontsize=8)\n",
    "    ax.set_xlabel(\"Sample Size (n)\", fontsize=10)\n",
    "    ax.set_ylabel(\"Spearman rho (SRI vs gap)\", fontsize=10)\n",
    "    ax.set_title(\"Scope-of-Validity: When Does the WRL Theory Work?\")\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(\"scope_validity.png\", dpi=FIGURE_DPI, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "plot_scope_validity(studies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ywcb83cvli",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T19:33:27.462738Z",
     "iopub.status.busy": "2026-02-22T19:33:27.462645Z",
     "iopub.status.idle": "2026-02-22T19:33:27.569744Z",
     "shell.execute_reply": "2026-02-22T19:33:27.569452Z"
    }
   },
   "outputs": [],
   "source": [
    "# ── Figure 6: Decision Tree ──\n",
    "def plot_decision_tree():\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    ax.set_xlim(0, 10)\n",
    "    ax.set_ylim(0, 10)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    ax.text(5, 9.5, \"Positional Encoding Selection\", ha=\"center\", fontsize=14, fontweight=\"bold\",\n",
    "            bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"#3498db\", alpha=0.3))\n",
    "    ax.text(5, 8, \"Compute SRI = K x delta_min\\nfor your graph\", ha=\"center\", fontsize=10,\n",
    "            bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"#f1c40f\", alpha=0.3))\n",
    "    ax.annotate(\"\", xy=(5, 8.5), xytext=(5, 9.1), arrowprops=dict(arrowstyle=\"->\"))\n",
    "\n",
    "    ax.text(2.5, 6, \"SRI < 1\\n(Low resolution)\", ha=\"center\", fontsize=9,\n",
    "            bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"#e74c3c\", alpha=0.3))\n",
    "    ax.text(7.5, 6, \"SRI >= 1\\n(Adequate resolution)\", ha=\"center\", fontsize=9,\n",
    "            bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"#2ecc71\", alpha=0.3))\n",
    "    ax.annotate(\"\", xy=(3.5, 6.5), xytext=(4.5, 7.6), arrowprops=dict(arrowstyle=\"->\"))\n",
    "    ax.annotate(\"\", xy=(6.5, 6.5), xytext=(5.5, 7.6), arrowprops=dict(arrowstyle=\"->\"))\n",
    "\n",
    "    ax.text(1, 4, \"Protein graphs:\\nUse LapPE\\n(best overall)\", ha=\"center\", fontsize=8,\n",
    "            bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"#9b59b6\", alpha=0.3))\n",
    "    ax.text(4, 4, \"Molecular graphs:\\nUse RWSE\\n(robust baseline)\", ha=\"center\", fontsize=8,\n",
    "            bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"#1abc9c\", alpha=0.3))\n",
    "    ax.text(7.5, 4, \"Use RWSE\\n(RWSE excels at\\nhigh resolution)\", ha=\"center\", fontsize=8,\n",
    "            bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"#2ecc71\", alpha=0.3))\n",
    "\n",
    "    ax.annotate(\"\", xy=(1.5, 4.5), xytext=(2, 5.5), arrowprops=dict(arrowstyle=\"->\"))\n",
    "    ax.annotate(\"\", xy=(3.5, 4.5), xytext=(3, 5.5), arrowprops=dict(arrowstyle=\"->\"))\n",
    "    ax.annotate(\"\", xy=(7.5, 4.5), xytext=(7.5, 5.5), arrowprops=dict(arrowstyle=\"->\"))\n",
    "\n",
    "    ax.text(5, 2, \"Key Finding: SRWE helps mainly on Peptides-struct (57.7% gap reduction)\\n\"\n",
    "                   \"but not consistently across all datasets.\\n\"\n",
    "                   \"RWSE remains the safest default for molecular graphs (ZINC).\",\n",
    "            ha=\"center\", fontsize=9, style=\"italic\",\n",
    "            bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"#ecf0f1\", alpha=0.5))\n",
    "    ax.set_title(\"Encoding Selection Decision Tree\", fontsize=13, fontweight=\"bold\")\n",
    "    fig.savefig(\"decision_tree.png\", dpi=FIGURE_DPI, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "plot_decision_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebgps1ene4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T19:33:27.571316Z",
     "iopub.status.busy": "2026-02-22T19:33:27.571166Z",
     "iopub.status.idle": "2026-02-22T19:33:27.728559Z",
     "shell.execute_reply": "2026-02-22T19:33:27.727883Z"
    }
   },
   "outputs": [],
   "source": [
    "# ── Figure 7: Encoding Performance Bars ──\n",
    "def plot_encoding_performance_bars(srwe_results):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(16, 6))\n",
    "\n",
    "    dataset_results = {}\n",
    "    for cond_name, cond_data in srwe_results.items():\n",
    "        ds = cond_data.get(\"dataset\", \"unknown\")\n",
    "        if ds not in dataset_results:\n",
    "            dataset_results[ds] = {}\n",
    "        for enc in [\"rwse\", \"lappe\", \"srwe_mpm\", \"srwe_tikhonov\", \"srwe\", \"none\",\n",
    "                     \"histogram\", \"moment_correction\", \"spectral_summary\", \"raw_weights\"]:\n",
    "            if enc in cond_data and cond_data[enc] is not None:\n",
    "                if enc not in dataset_results[ds]:\n",
    "                    dataset_results[ds][enc] = []\n",
    "                dataset_results[ds][enc].append(cond_data[enc])\n",
    "\n",
    "    plot_datasets = list(dataset_results.keys())[:MAX_BAR_CHART_DATASETS]\n",
    "    for ax_idx, ds in enumerate(plot_datasets):\n",
    "        if ax_idx >= len(axes):\n",
    "            break\n",
    "        ax = axes[ax_idx]\n",
    "        ds_data = dataset_results[ds]\n",
    "        enc_names = sorted(ds_data.keys())[:8]\n",
    "        means = [np.mean(ds_data[e]) for e in enc_names]\n",
    "        stds = [np.std(ds_data[e]) if len(ds_data[e]) > 1 else 0 for e in enc_names]\n",
    "\n",
    "        x = np.arange(len(enc_names))\n",
    "        ax.bar(x, means, yerr=stds, capsize=3, alpha=0.8, color=plt.cm.tab10(np.linspace(0, 1, len(enc_names))))\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(enc_names, rotation=45, ha=\"right\", fontsize=7)\n",
    "        ax.set_title(f\"{ds}\", fontsize=10, fontweight=\"bold\")\n",
    "        ax.set_ylabel(\"Performance\")\n",
    "\n",
    "    # Hide unused axes\n",
    "    for ax_idx in range(len(plot_datasets), len(axes)):\n",
    "        axes[ax_idx].axis(\"off\")\n",
    "\n",
    "    fig.suptitle(\"Encoding Performance Comparison Across Datasets\", fontsize=12, fontweight=\"bold\")\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(\"encoding_performance.png\", dpi=FIGURE_DPI, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "plot_encoding_performance_bars(srwe_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uj96p3ysbe",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Key results from the Grand Synthesis evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8inmzoodok",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T19:33:27.729860Z",
     "iopub.status.busy": "2026-02-22T19:33:27.729733Z",
     "iopub.status.idle": "2026-02-22T19:33:27.733728Z",
     "shell.execute_reply": "2026-02-22T19:33:27.733395Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "GRAND SYNTHESIS: WALK RESOLUTION LIMIT HYPOTHESIS ADJUDICATION\n",
      "======================================================================\n",
      "\n",
      "  Overall Verdict:       PARTIALLY_CONFIRMED\n",
      "  Overall Score:         0.458\n",
      "  Confirmation Score:    0.224\n",
      "  Disconf. Penalty:      0.003\n",
      "\n",
      "  Pooled rho:            0.1526 [0.0204, 0.2796]\n",
      "  I2 Heterogeneity:      99.0%\n",
      "  Number of studies:     26\n",
      "\n",
      "  CRITERION VERDICTS:\n",
      "  ------------------------------------------------------------------\n",
      "  C1_sri_gap_correlation                        not_confirmed             (conf=0.86)\n",
      "  C2_aliased_pairs_distinguishability           confirmed                 (conf=0.67)\n",
      "  C3_srwe_gap_reduction                         partially_confirmed       (conf=0.36)\n",
      "  D1_weak_correlation                           disconfirmed              (conf=0.24)\n",
      "  D2_resolution_mismatch                        not_confirmed             (conf=0.50)\n",
      "  D3_no_srwe_improvement                        partially_confirmed       (conf=0.50)\n",
      "\n",
      "  SRWE SCORECARD SUMMARY:\n",
      "  ------------------------------------------------------------------\n",
      "  Total comparisons: 74\n",
      "  Wins: 34, Losses: 32, Ties: 8\n",
      "\n",
      "  MODERATOR EFFECTS:\n",
      "  ------------------------------------------------------------------\n",
      "  dataset_domain            p=0.8189    \n",
      "  architecture              p=0.0010 ***\n",
      "  metric_type               p=0.0009 ***\n",
      "\n",
      "  SCOPE OF VALIDITY:\n",
      "  ------------------------------------------------------------------\n",
      "  Directional accuracy:  19.2%\n",
      "  Works in:              molecular, protein, synthetic\n",
      "  Fails in:              molecular, other, protein, synthetic\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ── Print Summary Table ──\n",
    "print(\"=\" * 70)\n",
    "print(\"GRAND SYNTHESIS: WALK RESOLUTION LIMIT HYPOTHESIS ADJUDICATION\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(f\"  Overall Verdict:       {overall['overall_verdict'].upper()}\")\n",
    "print(f\"  Overall Score:         {overall['overall_score']:.3f}\")\n",
    "print(f\"  Confirmation Score:    {overall['confirmation_score']:.3f}\")\n",
    "print(f\"  Disconf. Penalty:      {overall['disconfirmation_penalty']:.3f}\")\n",
    "print()\n",
    "print(f\"  Pooled rho:            {pooled['rho_pooled']:.4f} [{pooled['ci_low']:.4f}, {pooled['ci_high']:.4f}]\")\n",
    "print(f\"  I2 Heterogeneity:      {pooled['I2']:.1f}%\")\n",
    "print(f\"  Number of studies:     {pooled['k']}\")\n",
    "print()\n",
    "print(\"  CRITERION VERDICTS:\")\n",
    "print(\"  \" + \"-\" * 66)\n",
    "for key, v in verdicts.items():\n",
    "    print(f\"  {key:45s} {v['verdict']:25s} (conf={v['confidence']:.2f})\")\n",
    "print()\n",
    "print(\"  SRWE SCORECARD SUMMARY:\")\n",
    "print(\"  \" + \"-\" * 66)\n",
    "total_w = sum(sc[\"wins\"] for sc in scorecard.values())\n",
    "total_l = sum(sc[\"losses\"] for sc in scorecard.values())\n",
    "total_t = sum(sc[\"ties\"] for sc in scorecard.values())\n",
    "print(f\"  Total comparisons: {total_w + total_l + total_t}\")\n",
    "print(f\"  Wins: {total_w}, Losses: {total_l}, Ties: {total_t}\")\n",
    "print()\n",
    "print(\"  MODERATOR EFFECTS:\")\n",
    "print(\"  \" + \"-\" * 66)\n",
    "for mod_name, mod_data in moderators.items():\n",
    "    sig = \"***\" if mod_data.get(\"significant\") else \"   \"\n",
    "    print(f\"  {mod_name:25s} p={mod_data['p_value']:.4f} {sig}\")\n",
    "print()\n",
    "print(\"  SCOPE OF VALIDITY:\")\n",
    "print(\"  \" + \"-\" * 66)\n",
    "print(f\"  Directional accuracy:  {scope['directional_accuracy']:.1%}\")\n",
    "print(f\"  Works in:              {', '.join(scope['domains_where_works'])}\")\n",
    "print(f\"  Fails in:              {', '.join(scope['domains_where_fails'])}\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
